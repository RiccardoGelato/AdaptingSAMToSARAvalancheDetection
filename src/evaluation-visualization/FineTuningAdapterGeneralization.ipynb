{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "import os\n",
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from model.adapterModel import LitSamModel\n",
    "from utils.statistics import calculate_correlation\n",
    "from torch.utils.data import DataLoader\n",
    "from model.samDataset import SAMDataset3\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"   # maps logical GPU 0 -> physical GPU 1\n",
    "from helperFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the path of the script\n",
    "current_file = Path(__file__).resolve() # src/training/your_script.py\n",
    "\n",
    "# 2. Go up one level to 'src', then into 'config'\n",
    "config_path = current_file.parent.parent / \"config\" / \"config_general.yaml\"\n",
    "\n",
    "# 3. Load the YAML\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. Resolve the root of the project (one level above 'src')\n",
    "# This ensures that \"./data\" in the YAML is interpreted relative to the Project_Root\n",
    "PROJECT_ROOT = current_file.parent.parent.parent\n",
    "os.chdir(PROJECT_ROOT) \n",
    "\n",
    "# Extract paths from YAML\n",
    "DATA_DIR = config['paths']['data']\n",
    "CHECKPOINT_DIR = config['paths']['checkpoints']\n",
    "SAM_CHECKPOINT = config['paths']['sam_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test dataset\n",
    "\n",
    "test_dataset = load_from_disk(os.path.join(DATA_DIR, 'datasetTestFinal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SamModel, SamConfig, SamProcessor\n",
    "import torch\n",
    "from model.inputTypes import InputTypes\n",
    "\n",
    "\n",
    "sam_checkpoint = os.path.join(CHECKPOINT_DIR, 'sam-float-adapter-newbase-epoch=57-val_loss=0.224-val_iou=0.592.ckpt')\n",
    "# Create an instance of the model architecture with the loaded configuration\n",
    "#model = LitSamModel.load_from_checkpoint(sam_checkpoint, model_name=\"vit-b\", normalize = True, adapt_patch_embed = False, input_type = InputTypes.Normal)\n",
    "model = LitSamModel(model_name=\"vit_b\", normalize=True, learning_rate=1e-5, input_type=InputTypes.Normal, adapt = False)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "\n",
    "# set the device to cuda if available, otherwise use cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(mask1, mask2):\n",
    "\n",
    "    # Ensure the masks are PyTorch tensors\n",
    "    if isinstance(mask1, np.ndarray):\n",
    "        mask1 = torch.tensor(mask1)\n",
    "    if isinstance(mask2, np.ndarray):\n",
    "        mask2 = torch.tensor(mask2)\n",
    "        \n",
    "    # Ensure the masks are binary\n",
    "    mask1 = mask1 > 0\n",
    "    mask2 = mask2 > 0\n",
    "    \n",
    "    # Calculate the intersection and union\n",
    "    intersection = torch.logical_and(mask1, mask2)\n",
    "    union = torch.logical_or(mask1, mask2)\n",
    "    \n",
    "    # Compute the IoU\n",
    "    iou = torch.sum(intersection).float() / torch.sum(union).float()\n",
    "    \n",
    "    return iou, intersection, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the SAMDataset\n",
    "test_dataset_sam = SAMDataset3(dataset=test_dataset, processor=processor, augment=False, test = True, type = InputTypes.Normal)\n",
    "\n",
    "# Create a DataLoader instance for the validation dataset\n",
    "test_dataloader = DataLoader(test_dataset_sam, batch_size=5, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1)\n",
    "\n",
    "# Run the evaluation\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the stored results\n",
    "test_results = model.test_results\n",
    "ground_truth_masks = test_results['ground_truth_masks']\n",
    "predicted_masks = test_results['predicted_masks']\n",
    "individual_ious = test_results['individual_ious']\n",
    "bboxes = test_results['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_masks = np.concatenate(predicted_masks, axis=0)\n",
    "ground_truth_masks = np.concatenate(ground_truth_masks, axis=0)\n",
    "bounding_boxes = np.concatenate(bboxes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_zero_shot = []\n",
    "\n",
    "for index in range(len(test_dataset)):\n",
    "        mask = ground_truth_masks[index]\n",
    "        sam_seg = predicted_masks[index]\n",
    "\n",
    "        sam_seg_prob = torch.sigmoid(torch.tensor(sam_seg))\n",
    "        # convert soft mask to hard mask\n",
    "        sam_seg_prob = sam_seg_prob.cpu().numpy().squeeze()\n",
    "        sam_seg = (sam_seg_prob > 0.5).astype(np.uint8)\n",
    "\n",
    "        # Calculate IoU\n",
    "        iou, intersection, union = calculate_iou(mask, sam_seg)\n",
    "\n",
    "        results_zero_shot.append({'mask': mask,\n",
    "                                  'calculated_mask': sam_seg, \n",
    "                                  'intersection': intersection.cpu().squeeze().numpy(), \n",
    "                                  'union': union.cpu().squeeze().numpy(), \n",
    "                                  'iou': iou.cpu().numpy(),\n",
    "                                  'empty': False, \n",
    "                                  'bbox': bounding_boxes[index],\n",
    "                                  'image_id': index,\n",
    "                                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove exemples with bounding boxes (0,0,512,512)\n",
    "results_zero_shot_copy = results_zero_shot.copy()\n",
    "results_zero_shot = [res for res in results_zero_shot if not (res['bbox'] == [0, 0, 1024, 1024]).all()]\n",
    "results_zero_shot_general = [res for res in results_zero_shot_copy if (res['bbox'] == [0, 0, 1024, 1024]).all()]\n",
    "\n",
    "results, metrics =calculate_pixel_based_metrics(results_zero_shot)\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "results, metrics =calculate_pixel_based_metrics(results_zero_shot_general)\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "results_zero_shot = results_zero_shot_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "df_finetune = pd.DataFrame(results_zero_shot)\n",
    "\n",
    "# Save the DataFrame to a file (optional)\n",
    "#df_finetune.to_pickle('dataframe_name.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with None IoU values\n",
    "df_filtered = df_finetune.dropna(subset=['iou'])\n",
    "\n",
    "\n",
    "# Create a boolean mask for rows with bbox (0,0,512,512) using apply\n",
    "mask_bbox = df_filtered['bbox'].apply(\n",
    "    lambda b: np.all(np.array(b) == np.array((0, 0, 1024, 1024)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to exclude rows with bbox (0,0,512,512)\n",
    "\n",
    "df_filtered = df_filtered[~mask_bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_filtered = df_filtered[mask_bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract IoU values from the filtered DataFrame\n",
    "iou_values = df_filtered['iou'].tolist()\n",
    "#iou_values = individual_ious\n",
    "\n",
    "# Calculate the average IoU\n",
    "average_iou = sum(iou_values) / len(iou_values)\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(iou_values)), iou_values, color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU for Baseline (Pretrain)')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(iou_values)), iou_values, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU for Baseline (Pretrain)')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming iou_values is a list of IoU scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(iou_values, bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('IoU')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'IoU for Baseline (Pretrain)')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the area of each mask\n",
    "df_filtered['mask_area'] = df_filtered['mask'].apply(lambda mask: np.sum(mask))\n",
    "\n",
    "# Filter out rows where the mask area is above 5000\n",
    "df_filtered2 = df_filtered[df_filtered['mask_area'] <= 1000]\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_filtered2['mask_area'], df_filtered2['iou'], marker='o', color='blue')\n",
    "plt.xlabel('Mask Area')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU vs. Mask Area')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a scatter plot with a logarithmic scale for the mask area axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_filtered['mask_area'], df_filtered['iou'], marker='o', color='blue')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Mask Area (log scale)')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU vs. Mask Area')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['bbox'] = df_filtered['bbox'].apply(lambda b: np.squeeze(b) if np.array(b).ndim == 2 else b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the area of each bounding box (assumes bbox format is (x, y, w, h))\n",
    "#df_filtered['bbox_area'] = df_filtered['bbox'].apply(lambda b: b[2] * b[3] if (b is not None and len(b) == 4) else None)\n",
    "\n",
    "df_filtered['bbox_area'] = df_filtered['bbox'].apply(\n",
    "    lambda b: (b[2] - b[0]) * (b[3] - b[1]) / 4 if (b is not None and len(b) == 4) else None\n",
    ")\n",
    "\n",
    "# Compute the ratio of bounding box area to mask area\n",
    "df_filtered['area_ratio'] = df_filtered['mask_area'] / df_filtered['bbox_area'] \n",
    "\n",
    "# Drop rows with missing values in area_ratio or IoU to ensure clean plotting\n",
    "df_plot = df_filtered.dropna(subset=['area_ratio', 'iou'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['area_ratio'], df_plot['iou'], marker='o', color='blue')\n",
    "plt.xlabel('Bounding Box Area / Mask Area')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU vs. Area Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Assume area_ratio and iou have been computed as before and stored in df_plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['area_ratio'], df_plot['iou'], marker='o', color='blue')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Bounding Box Area / Mask Area (log scale)')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU vs. Area Ratio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Function to count the number of disconnected regions (avalanches) in a mask.\n",
    "# Assumes mask is a binary or grayscale image.\n",
    "def count_avalanches(mask):\n",
    "    # Ensure the mask is binary: any non-zero pixel is considered part of an avalanche.\n",
    "    binary_mask = (mask > 0).astype(np.uint8)\n",
    "    # cv2.connectedComponents returns (num_labels, labels); subtract 1 for the background.\n",
    "    num_labels, _ = cv2.connectedComponents(binary_mask)\n",
    "    return num_labels - 1  # subtract one for the background\n",
    "\n",
    "# Compute the number of avalanches for each mask and store in a new column.\n",
    "# This assumes the 'mask' column in df_filtered contains the mask array.\n",
    "df_filtered['num_avalanches'] = df_filtered['mask'].apply(lambda m: count_avalanches(m) if m is not None else None)\n",
    "\n",
    "# Drop rows with missing values in num_avalanches or IoU.\n",
    "df_plot = df_filtered.dropna(subset=['num_avalanches', 'iou'])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_plot['num_avalanches'], df_plot['iou'], marker='o', color='blue')\n",
    "plt.xlabel('Number of Avalanches in Mask')\n",
    "plt.ylabel('IoU')\n",
    "plt.title('IoU vs. Number of Avalanches')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask_area_threshold = 100  # set your desired threshold\n",
    "\n",
    "# Filter out rows where mask_area or IoU are missing and then select only those with mask_area above the threshold.\n",
    "df_filtered_threshold = df_filtered.dropna(subset=['mask_area', 'iou'])\n",
    "df_filtered_threshold = df_filtered_threshold[df_filtered_threshold['mask_area'] > mask_area_threshold]\n",
    "\n",
    "# Extract IoU values from the filtered DataFrame\n",
    "iou_values = df_filtered_threshold['iou'].tolist()\n",
    "\n",
    "# Calculate the average IoU (ensure there is at least one value)\n",
    "average_iou = sum(iou_values) / len(iou_values) if iou_values else 0\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(iou_values)), iou_values, color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('IoU')\n",
    "plt.title(f'IoU Values for Samples with Mask Area > {mask_area_threshold}')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()\n",
    "\n",
    "# Create a line plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(iou_values)), iou_values, marker='o', linestyle='-', color='blue')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('IoU')\n",
    "plt.title(f'IoU Values for Samples with Mask Area > {mask_area_threshold}')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()\n",
    "\n",
    "# Assuming iou_values is a list of IoU scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(iou_values, bins=20, color='blue', alpha=0.7)\n",
    "plt.xlabel('IoU')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Histogram of IoU Scores (Mask Area > {mask_area_threshold})')\n",
    "plt.text(0.5, 0.95, f'Average IoU: {average_iou:.4f}', ha='center', va='center', transform=plt.gca().transAxes, fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered['mask_area'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['mask_area'] = df_filtered['mask'].apply(lambda mask: np.sum(np.array(mask, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numpy arrays with a numeric dtype\n",
    "mask_area_numeric = np.asarray(df_filtered['mask_area'].values, dtype=np.float32)\n",
    "iou_numeric = np.asarray(df_filtered['iou'].values, dtype=np.float32)\n",
    "\n",
    "corr, p_value = calculate_correlation(mask_area_numeric, iou_numeric)\n",
    "print(f\"Correlation between mask area and IoU: {corr}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no zeros (to avoid log issues) by adding a small constant if needed.\n",
    "epsilon = 1e-8\n",
    "mask_area_log = np.log(mask_area_numeric + epsilon)\n",
    "\n",
    "corr, p_value = calculate_correlation(mask_area_log, iou_numeric)\n",
    "print(f\"Correlation on log-transformed values: {corr}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numpy arrays with a numeric dtype\n",
    "num_avalanches_numric = np.asarray(df_filtered['num_avalanches'].values, dtype=np.float32)\n",
    "iou_numeric = np.asarray(df_filtered['iou'].values, dtype=np.float32)\n",
    "\n",
    "corr, p_value = calculate_correlation(num_avalanches_numric, iou_numeric)\n",
    "print(f\"Correlation between number of avalanches and IoU: {corr}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numpy arrays with a numeric dtype\n",
    "area_ratio_numeric = np.asarray(df_filtered['area_ratio'].values, dtype=np.float32)\n",
    "iou_numeric = np.asarray(df_filtered['iou'].values, dtype=np.float32)\n",
    "\n",
    "corr, p_value = calculate_correlation(area_ratio_numeric, iou_numeric)\n",
    "print(f\"Correlation between area ratio and IoU: {corr}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure no zeros (to avoid log issues) by adding a small constant if needed.\n",
    "epsilon = 1e-8\n",
    "area_ratio_log = np.log(area_ratio_numeric + epsilon)\n",
    "\n",
    "corr, p_value = calculate_correlation(area_ratio_log, iou_numeric)\n",
    "print(f\"Correlation on log-transformed values: {corr}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find bounding boxes for each group of disconnected white pixels\n",
    "def find_bounding_boxes(mask):\n",
    "    # Ensure the mask is an 8-bit image.\n",
    "    if mask.dtype != \"uint8\":\n",
    "        # If mask values are in range 0-1, scale them by 255\n",
    "        if mask.max() <= 1:\n",
    "            mask_uint8 = (mask * 255).astype('uint8')\n",
    "        else:\n",
    "            mask_uint8 = mask.astype('uint8')\n",
    "    else:\n",
    "        mask_uint8 = mask\n",
    "\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute bounding boxes for each contour and convert (x, y, w, h) to (x_min, y_min, x_max, y_max)\n",
    "    bounding_boxes = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        bounding_boxes.append([x, y, x + w, y + h])\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.3\n",
    "\n",
    "for res in results_zero_shot:\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    # The predicted and ground truth avalanche masks\n",
    "    pred_mask = res['calculated_mask']\n",
    "    true_mask = res['mask']\n",
    "\n",
    "    original_bbox = find_bounding_boxes(true_mask)\n",
    "    pred_bbox = find_bounding_boxes(pred_mask)\n",
    "\n",
    "    for bbox in original_bbox:\n",
    "        predicted = False\n",
    "        for pred in pred_bbox:\n",
    "\n",
    "            # Assuming each bbox is [x_min, y_min, x_max, y_max]\n",
    "            x_left = max(bbox[0], pred[0])\n",
    "            y_top = max(bbox[1], pred[1])\n",
    "            x_right = min(bbox[2], pred[2])\n",
    "            y_bottom = min(bbox[3], pred[3])\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            if x_right < x_left or y_bottom < y_top:\n",
    "                overlap_area = 0\n",
    "            else:\n",
    "                overlap_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "            overlap = overlap_area / ((bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) )#+ (pred[2] - pred[0]) * (pred[3] - pred[1]) - overlap_area)\n",
    "            if overlap > treshold:\n",
    "                predicted = True\n",
    "                break\n",
    "        if not predicted:\n",
    "            false_negatives.append(bbox)\n",
    "    for bbox in pred_bbox:\n",
    "        original = False\n",
    "        for originalbbox in original_bbox:\n",
    "            # Assuming each bbox is [x_min, y_min, x_max, y_max]\n",
    "            x_left = max(bbox[0], originalbbox[0])\n",
    "            y_top = max(bbox[1], originalbbox[1])\n",
    "            x_right = min(bbox[2], originalbbox[2])\n",
    "            y_bottom = min(bbox[3], originalbbox[3])\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            if x_right < x_left or y_bottom < y_top:\n",
    "                overlap_area = 0\n",
    "            else:\n",
    "                overlap_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "            overlap = overlap_area / ((bbox[2] - bbox[0]) * (bbox[3] - bbox[1]) )#+ (originalbbox[2] - originalbbox[0]) * (originalbbox[3] - originalbbox[1]) - overlap_area)\n",
    "            if overlap > treshold:\n",
    "                original = True\n",
    "                break\n",
    "        if not original:\n",
    "            false_positives.append(bbox)\n",
    "            \n",
    "    # Add the results into the current dictionary element\n",
    "    res['false_negatives'] = false_negatives\n",
    "    res['false_positives'] = false_positives\n",
    "    res['percentage_false_negatives'] = len(false_negatives) / len(original_bbox) if len(original_bbox) > 0 else 0\n",
    "    res['percentage_false_positives'] = len(false_positives) / len(pred_bbox) if len(pred_bbox) > 0 else 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = results_zero_shot[0]\n",
    "\n",
    "pred_mask = res['calculated_mask']\n",
    "true_mask = res['mask']\n",
    "\n",
    "print(\"Shape of predicted mask:\", pred_mask.shape)\n",
    "print(\"Shape of true mask:\", true_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treshold = 0.3\n",
    "\n",
    "for res in results_zero_shot:\n",
    "    false_positives = []\n",
    "    false_negatives = []\n",
    "    # The predicted and ground truth avalanche masks\n",
    "    pred_mask = res['calculated_mask']\n",
    "    true_mask = res['mask']\n",
    "\n",
    "    original_bbox = find_bounding_boxes(true_mask)\n",
    "    pred_bbox = find_bounding_boxes(pred_mask)\n",
    "\n",
    "    for bbox in original_bbox:\n",
    "        predicted = False\n",
    "        for pred in pred_bbox:\n",
    "\n",
    "            pred_mask_local = np.zeros_like(pred_mask)\n",
    "            pred_mask_local[pred[1]:pred[3], pred[0]:pred[2]] = pred_mask[pred[1]:pred[3], pred[0]:pred[2]]\n",
    "\n",
    "            original_mask_local = np.zeros_like(true_mask)\n",
    "            original_mask_local[bbox[1]:bbox[3], bbox[0]:bbox[2]] = true_mask[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            overlap_area = np.sum(np.logical_and(pred_mask_local, original_mask_local))\n",
    "            original_area = np.sum(original_mask_local)\n",
    "\n",
    "            overlap = overlap_area / original_area if original_area > 0 else 0\n",
    "            if overlap > treshold:\n",
    "                predicted = True\n",
    "                break\n",
    "        if not predicted:\n",
    "            false_negatives.append(bbox)\n",
    "    for bbox in pred_bbox:\n",
    "        original = False\n",
    "        for originalbbox in original_bbox:\n",
    "            \n",
    "            pred_mask_local = np.zeros_like(pred_mask)\n",
    "            pred_mask_local[bbox[1]:bbox[3], bbox[0]:bbox[2]] = pred_mask[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "\n",
    "            original_mask_local = np.zeros_like(true_mask)\n",
    "            original_mask_local[originalbbox[1]:originalbbox[3], originalbbox[0]:originalbbox[2]] = true_mask[originalbbox[1]:originalbbox[3], originalbbox[0]:originalbbox[2]]\n",
    "\n",
    "            # Calculate the overlap area\n",
    "            overlap_area = np.sum(np.logical_and(pred_mask_local, original_mask_local))\n",
    "            pred_area = np.sum(pred_mask_local)\n",
    "\n",
    "            overlap = overlap_area / pred_area if pred_area > 0 else 0\n",
    "            if overlap > treshold:\n",
    "                original = True\n",
    "                break\n",
    "        if not original:\n",
    "            false_positives.append(bbox)\n",
    "            \n",
    "    # Add the results into the current dictionary element\n",
    "    res['false_negatives'] = false_negatives\n",
    "    res['false_positives'] = false_positives\n",
    "    res['percentage_false_negatives'] = len(false_negatives) / len(original_bbox) if len(original_bbox) > 0 else 0\n",
    "    res['percentage_false_positives'] = len(false_positives) / len(pred_bbox) if len(pred_bbox) > 0 else 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove exemples with bounding boxes (0,0,512,512)\n",
    "results_zero_shot_copy = results_zero_shot.copy()\n",
    "results_zero_shot = [res for res in results_zero_shot if not (res['bbox'] == [0, 0, 1024, 1024]).all()]\n",
    "results_zero_shot_general = [res for res in results_zero_shot_copy if (res['bbox'] == [0, 0, 1024, 1024]).all()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_zero_shot = results_zero_shot_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell: Plot the percentage of false positives and false negatives with averages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Extract percentages from the results\n",
    "false_negatives_pct = [res.get('percentage_false_negatives', 0) for res in results_zero_shot]\n",
    "false_positives_pct = [res.get('percentage_false_positives', 0) for res in results_zero_shot]\n",
    "indices = np.arange(len(results_zero_shot))\n",
    "\n",
    "# Compute average percentages\n",
    "avg_false_negatives = np.mean(false_negatives_pct)\n",
    "avg_false_positives = np.mean(false_positives_pct)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(indices - 0.15, false_negatives_pct, width=0.3, color='red', label='False Negatives')\n",
    "plt.bar(indices + 0.15, false_positives_pct, width=0.3, color='blue', label='False Positives')\n",
    "\n",
    "# Plot average lines\n",
    "plt.axhline(avg_false_negatives, color='darkred', linestyle='--', \n",
    "            label=f'Avg False Negatives: {avg_false_negatives:.2f}')\n",
    "plt.axhline(avg_false_positives, color='darkblue', linestyle='--', \n",
    "            label=f'Avg False Positives: {avg_false_positives:.2f}')\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title(f'Percentage of False Negatives and False Positives per Sample (Baseline, Treshold = {treshold})')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell: Plot the percentage of false positives and false negatives with averages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Extract percentages from the results\n",
    "false_negatives_pct = [res.get('percentage_false_negatives', 0) for res in results_zero_shot_general]\n",
    "false_positives_pct = [res.get('percentage_false_positives', 0) for res in results_zero_shot_general]\n",
    "indices = np.arange(len(results_zero_shot_general))\n",
    "\n",
    "# Compute average percentages\n",
    "avg_false_negatives = np.mean(false_negatives_pct)\n",
    "avg_false_positives = np.mean(false_positives_pct)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(indices - 0.15, false_negatives_pct, width=0.3, color='red', label='False Negatives')\n",
    "plt.bar(indices + 0.15, false_positives_pct, width=0.3, color='blue', label='False Positives')\n",
    "\n",
    "# Plot average lines\n",
    "plt.axhline(avg_false_negatives, color='darkred', linestyle='--', \n",
    "            label=f'Avg False Negatives: {avg_false_negatives:.2f}')\n",
    "plt.axhline(avg_false_positives, color='darkblue', linestyle='--', \n",
    "            label=f'Avg False Positives: {avg_false_positives:.2f}')\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Percentage of False Negatives and False Positives per Sample')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell: Visualization of samples with high error percentages including the associated image \n",
    "# and original bounding box (green) in ground truth and prediction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define a threshold for high error (e.g., 50% error for this example)\n",
    "threshold = 0.4\n",
    "\n",
    "# Filter samples with either false negative or false positive percentage above the threshold\n",
    "high_error_results = [\n",
    "    res for res in results_zero_shot \n",
    "    if res.get('percentage_false_negatives', 0) > threshold or res.get('percentage_false_positives', 0) > threshold\n",
    "]\n",
    "\n",
    "print(f\"Number of high error samples: {len(high_error_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_test = load_from_disk('/home/gelato/Avalanche-Segmentation-with-Sam/code/dataprocessing/datasetTestDEMFloat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, res in enumerate(high_error_results):\n",
    "\n",
    "    if idx >= 10:  # Limit visualization to the first 10 high error samples\n",
    "        break\n",
    "    \n",
    "    # Create a row of 3 subplots:\n",
    "    # Left: Ground Truth with false negatives and original bbox\n",
    "    # Middle: Associated original image\n",
    "    # Right: Predicted mask with false positives and original bbox\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    # --- Left: Ground truth mask with false negative outlines and original bounding box in green --- \n",
    "    mask = res['mask']\n",
    "    if mask.ndim == 2:\n",
    "        gt_img = (mask * 255).astype(np.uint8)\n",
    "        gt_img = cv2.cvtColor(gt_img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        gt_img = mask.copy()\n",
    "    ax1.imshow(gt_img)\n",
    "    ax1.set_title(\"Ground Truth with False Negatives\")\n",
    "    \n",
    "    # Draw the original bounding box in green\n",
    "    \n",
    "    orig_bbox = res['bbox']/2\n",
    "    rect_orig = patches.Rectangle((orig_bbox[0], orig_bbox[1]),\n",
    "                                    orig_bbox[2] - orig_bbox[0],                                   \n",
    "                                    orig_bbox[3] - orig_bbox[1],\n",
    "                                    linewidth=2,\n",
    "                                    edgecolor='g',\n",
    "                                    facecolor='none')\n",
    "    rect_orig2 = patches.Rectangle((orig_bbox[0], orig_bbox[1]),\n",
    "                                    orig_bbox[2] - orig_bbox[0],                                   \n",
    "                                    orig_bbox[3] - orig_bbox[1],\n",
    "                                    linewidth=2,\n",
    "                                    edgecolor='g',\n",
    "                                    facecolor='none')\n",
    "    \n",
    "    ax1.add_patch(rect_orig)\n",
    "    \n",
    "    # Draw false negative bounding boxes in red\n",
    "    for bbox in res.get('false_negatives', []):\n",
    "        rect_fn = patches.Rectangle((bbox[0], bbox[1]),\n",
    "                                    bbox[2] - bbox[0],\n",
    "                                    bbox[3] - bbox[1],\n",
    "                                    linewidth=2,\n",
    "                                    edgecolor='r',\n",
    "                                    facecolor='none')\n",
    "        ax1.add_patch(rect_fn)\n",
    "   \n",
    "    # --- Middle: Associated original image ---\n",
    "    orig_image =  test_dataset_test[res['image_id']]['image'] if 'image_id' in res else None\n",
    "    if not isinstance(orig_image, np.ndarray):\n",
    "        orig_image = np.array(orig_image)\n",
    "    orig_image_disp = (orig_image * 255).astype(np.uint8)\n",
    "    ax2.imshow(orig_image_disp)\n",
    "    ax2.set_title(\"Original Image\")\n",
    "    \n",
    "    # --- Right: Predicted mask with false positive outlines and original bounding box in green ---\n",
    "    pred_mask = res['calculated_mask']\n",
    "    if pred_mask.ndim == 2:\n",
    "        pred_img = (pred_mask * 255).astype(np.uint8)\n",
    "        pred_img = cv2.cvtColor(pred_img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        pred_img = pred_mask.copy()\n",
    "    ax3.imshow(pred_img)\n",
    "    ax3.set_title(\"Prediction with False Positives\")\n",
    "    \n",
    "    # Draw the original bounding box in green \n",
    "    ax3.add_patch(rect_orig2)\n",
    "    \n",
    "    # Draw false positive bounding boxes in blue\n",
    "    for bbox in res.get('false_positives', []):\n",
    "        rect_fp = patches.Rectangle((bbox[0], bbox[1]),\n",
    "                                    bbox[2] - bbox[0],\n",
    "                                    bbox[3] - bbox[1],\n",
    "                                    linewidth=2,\n",
    "                                    edgecolor='b',\n",
    "                                    facecolor='none')\n",
    "        ax3.add_patch(rect_fp)\n",
    "    \n",
    "    # Hide axis from all subplots for clarity\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    save_path = 'images/adapters/falsepn/normalbox'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    #plt.savefig(f'{save_path}/{idx}.png')\n",
    "    plt.show()\n",
    "    plt.close(fig)  # Close the figure to free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New cell: Visualization of samples with high error percentages including the associated image \n",
    "# and original bounding box (green) in ground truth and prediction\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define a threshold for high error (e.g., 50% error for this example)\n",
    "threshold = 0.5\n",
    "\n",
    "# Filter samples with either false negative or false positive percentage above the threshold\n",
    "high_error_results = [\n",
    "    res for res in results_zero_shot_general\n",
    "    #if res.get('percentage_false_negatives', 0) > threshold or res.get('percentage_false_positives', 0) > threshold\n",
    "]\n",
    "\n",
    "print(f\"Number of high error samples: {len(high_error_results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20\n",
    "for idx, res in enumerate(high_error_results):\n",
    "\n",
    "    if idx >= 30:  # Limit visualization to the first 30 high error samples\n",
    "        break\n",
    "    if idx <15:\n",
    "        continue\n",
    "    \n",
    "    # Create a row of 3 subplots:\n",
    "    # Left: Ground Truth with false negatives and original bbox\n",
    "    # Middle: Associated original image\n",
    "    # Right: Predicted mask with false positives and original bbox\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    # --- Left: Ground truth mask with false negative outlines and original bounding box in green --- \n",
    "    mask = res['mask']\n",
    "    if mask.ndim == 2:\n",
    "        gt_img = (mask * 255).astype(np.uint8)\n",
    "        gt_img = cv2.cvtColor(gt_img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        gt_img = mask.copy()\n",
    "    ax1.imshow(gt_img)\n",
    "    ax1.set_title(\"Ground Truth\")\n",
    "    \n",
    "    # Draw the original bounding box in green\n",
    "    \n",
    "    orig_bbox = res['bbox'][0]/2\n",
    "    orig_bbox = orig_bbox - 0.5\n",
    "    rect_orig = patches.Rectangle((orig_bbox[0], orig_bbox[1]),\n",
    "                                    orig_bbox[2] - orig_bbox[0],                                   \n",
    "                                    orig_bbox[3] - orig_bbox[1],\n",
    "                                    linewidth=3,\n",
    "                                    edgecolor='g',\n",
    "                                    facecolor='none')\n",
    "    rect_orig2 = patches.Rectangle((orig_bbox[0], orig_bbox[1]),\n",
    "                                    orig_bbox[2] - orig_bbox[0],                                   \n",
    "                                    orig_bbox[3] - orig_bbox[1],\n",
    "                                    linewidth=3,\n",
    "                                    edgecolor='g',\n",
    "                                    facecolor='none')\n",
    "    \n",
    "    ax1.add_patch(rect_orig)\n",
    "   \n",
    "    # --- Middle: Associated original image ---\n",
    "    orig_image =  test_dataset_test[res['image_id']]['image'] if 'image_id' in res else None\n",
    "    if not isinstance(orig_image, np.ndarray):\n",
    "        orig_image = np.array(orig_image)\n",
    "    orig_image_disp = (orig_image * 255).astype(np.uint8)\n",
    "    #Substitute DEM with first channel of the image\n",
    "    orig_image_disp[:,:,2] = orig_image_disp[:, :, 0]\n",
    "    \n",
    "    ax2.imshow(orig_image_disp)\n",
    "    ax2.set_title(\"Image\")\n",
    "    \n",
    "    # --- Right: Predicted mask with false positive outlines and original bounding box in green ---\n",
    "    pred_mask = res['calculated_mask']\n",
    "    if pred_mask.ndim == 2:\n",
    "        pred_img = (pred_mask * 255).astype(np.uint8)\n",
    "        pred_img = cv2.cvtColor(pred_img, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        pred_img = pred_mask.copy()\n",
    "    ax3.imshow(pred_img)\n",
    "    ax3.set_title(\"Prediction\")\n",
    "    \n",
    "    # Draw the original bounding box in green \n",
    "    ax3.add_patch(rect_orig2)\n",
    "    \n",
    "    # Draw false positive bounding boxes in blue\n",
    "    for bbox in res.get('false_positives', []):\n",
    "        rect_fp = patches.Rectangle((bbox[0], bbox[1]),\n",
    "                                    bbox[2] - bbox[0],\n",
    "                                    bbox[3] - bbox[1],\n",
    "                                    linewidth=2,\n",
    "                                    edgecolor='b',\n",
    "                                    facecolor='none')\n",
    "        ax3.add_patch(rect_fp)\n",
    "    \n",
    "    # Hide axis from all subplots for clarity\n",
    "    for ax in (ax1, ax2, ax3):\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    save_path = 'images/adapters/falsepn/fullimagebox'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    #plt.savefig(f'{save_path}/{idx}.png')\n",
    "    plt.show()\n",
    "    plt.close(fig)  # Close the figure to free memory"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
