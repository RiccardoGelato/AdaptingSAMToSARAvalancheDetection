{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "import os\n",
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from model.adapterModel import LitSamModel, SAMDataset\n",
    "from utils.statistics import calculate_correlation\n",
    "from helperFunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the path of the script\n",
    "current_file = Path(__file__).resolve() # src/training/your_script.py\n",
    "\n",
    "# 2. Go up one level to 'src', then into 'config'\n",
    "config_path = current_file.parent.parent / \"config\" / \"config_general.yaml\"\n",
    "\n",
    "# 3. Load the YAML\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. Resolve the root of the project (one level above 'src')\n",
    "# This ensures that \"./data\" in the YAML is interpreted relative to the Project_Root\n",
    "PROJECT_ROOT = current_file.parent.parent.parent\n",
    "os.chdir(PROJECT_ROOT) \n",
    "\n",
    "# Extract paths from YAML\n",
    "DATA_DIR = config['paths']['data']\n",
    "CHECKPOINT_DIR = config['paths']['checkpoints']\n",
    "SAM_CHECKPOINT = config['paths']['sam_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the test dataset\n",
    "\n",
    "test_dataset = load_from_disk(os.path.join(DATA_DIR, 'datasetTestMetDemSlopeFiltered'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset keys:\", test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SamModel, SamConfig, SamProcessor\n",
    "import torch\n",
    "\n",
    "sam_checkpoint = os.path.join(CHECKPOINT_DIR, \"sam-float-adapter-metnormalized-epoch=36-val_loss=0.224-val_iou=0.588.ckpt\")\n",
    "\n",
    "# Create an instance of the model architecture with the loaded configuration\n",
    "model = LitSamModel.load_from_checkpoint_strictless(sam_checkpoint, model_name=\"vit-b\", normalize = True)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")\n",
    "\n",
    "# set the device to cuda if available, otherwise use cpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(mask1, mask2):\n",
    "\n",
    "    # Ensure the masks are PyTorch tensors\n",
    "    if isinstance(mask1, np.ndarray):\n",
    "        mask1 = torch.tensor(mask1)\n",
    "    if isinstance(mask2, np.ndarray):\n",
    "        mask2 = torch.tensor(mask2)\n",
    "        \n",
    "    # Ensure the masks are binary\n",
    "    mask1 = mask1 > 0\n",
    "    mask2 = mask2 > 0\n",
    "    \n",
    "    # Calculate the intersection and union\n",
    "    intersection = torch.logical_and(mask1, mask2)\n",
    "    union = torch.logical_or(mask1, mask2)\n",
    "    \n",
    "    # Compute the IoU\n",
    "    iou = torch.sum(intersection).float() / torch.sum(union).float()\n",
    "    \n",
    "    return iou, intersection, union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create an instance of the SAMDataset\n",
    "test_dataset_sam = SAMDataset(dataset=test_dataset, processor=processor, augment=False)\n",
    "\n",
    "# Create a DataLoader instance for the validation dataset\n",
    "test_dataloader = DataLoader(test_dataset_sam, batch_size=5, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create an instance of the SAMDataset\n",
    "test_dataset_sam_meteo = SAMDataset(dataset=test_dataset, processor=processor, augment=False, test_meteo=True)\n",
    "\n",
    "# Create a DataLoader instance for the validation dataset\n",
    "test_dataloader_meteo = DataLoader(test_dataset_sam_meteo, batch_size=5, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1)\n",
    "\n",
    "# Run the evaluation\n",
    "trainer.test(model, dataloaders=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a trainer\n",
    "trainer2 = pl.Trainer(accelerator='gpu', devices=1)\n",
    "\n",
    "# Run the evaluation\n",
    "trainer2.test(model, dataloaders=test_dataloader_meteo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the stored results\n",
    "test_results = model.test_results\n",
    "ground_truth_masks = test_results['ground_truth_masks']\n",
    "predicted_masks = test_results['predicted_masks']\n",
    "individual_ious = test_results['individual_ious']\n",
    "bboxes = test_results['bboxes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_masks = np.concatenate(predicted_masks, axis=0)\n",
    "ground_truth_masks = np.concatenate(ground_truth_masks, axis=0)\n",
    "bounding_boxes = np.concatenate(bboxes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_zero_shot = generate_results(test_dataset, ground_truth_masks, predicted_masks, bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "df_finetune = pd.DataFrame(results_zero_shot)\n",
    "\n",
    "# Save the DataFrame to a file (optional)\n",
    "#df_finetune.to_pickle('dataframe_name.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows with None IoU values\n",
    "df_filtered = df_finetune.dropna(subset=['iou'])\n",
    "\n",
    "\n",
    "# Create a boolean mask for rows with bbox (0,0,512,512) using apply\n",
    "mask_bbox = df_filtered['bbox'].apply(\n",
    "    lambda b: np.all(np.array(b) == np.array((0, 0, 1024, 1024)))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to exclude rows with bbox (0,0,512,512)\n",
    "\n",
    "df_filtered = df_filtered[~mask_bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "df_filtered = df_filtered[mask_bbox]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_statistics(df_filtered, model_name='NoMeteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_statistics(df_filtered, model_name='Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask_area_vs_iou(df_filtered, model_name='Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_vs_area_ratio(df_filtered, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_vs_num_avalanches(df_filtered, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_for_mask_area(df_filtered, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered['mask_area'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['mask_area'] = df_filtered['mask'].apply(lambda mask: np.sum(np.array(mask, dtype=np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mask_area_iou_correlation(df_filtered, calculate_correlation, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_mask_area_iou_correlation(df_filtered, calculate_correlation, model_name='No Meteo', scale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_num_avalanche_iou_correlation(df_filtered, calculate_correlation, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_area_ratio_iou_correlation(df_filtered, calculate_correlation, model_name='No Meteo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_area_ratio_iou_correlation(df_filtered, calculate_correlation, model_name='No Meteo', scale='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a file (optional)\n",
    "df_filtered.to_pickle('dataframe_bestadaptersmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finetune = df_finetune = pd.read_pickle('dataframe_bestadaptersmodel.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_zero_shot = compute_error_percentages(results_zero_shot, threshold=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_false_pos_neg_percentages(results_zero_shot,treshold= 0.3, model_name = 'No Meteo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
