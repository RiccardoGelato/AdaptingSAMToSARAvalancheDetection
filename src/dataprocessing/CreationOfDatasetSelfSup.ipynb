{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "from datasets import Dataset, load_from_disk\n",
    "import rcsHandlingFunctions as rcs\n",
    "import creationOfDataframe as cdf\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from sam.modeling.PMD_features import PMD_features\n",
    "from dataprocessing.slope import calculate_slope\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"\"\n",
    "\n",
    "# Get all dem paths\n",
    "dem_paths = cdf.get_all_image_paths(root_dir, ['dem.tif'])\n",
    "\n",
    "# Get all rcs paths\n",
    "rcs_paths = cdf.get_all_image_paths(root_dir, ['rcs.tif'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of rcs: \", len(rcs_paths))\n",
    "print(\"Number of dem: \", len(dem_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the occurrences of each rcs path\n",
    "rcs_counter = Counter(rcs_paths)\n",
    "\n",
    "# Collect the duplicates (paths that appear more than once)\n",
    "duplicates = [path for path, count in rcs_counter.items() if count > 1]\n",
    "\n",
    "print(\"Duplicate rcs paths:\", duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dem_rcs_paths = list(zip(dem_paths, rcs_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to substitute DEM data into the image\n",
    "def substitute_dem(image, dem_data, channel=2):\n",
    "    \"\"\"\n",
    "    Substitute one of the layers of the image with the DEM data.\n",
    "    Args:\n",
    "        image (np.ndarray): The original image.\n",
    "        dem_data (np.ndarray): The DEM data.\n",
    "        channel (int): The channel to be replaced with DEM data.\n",
    "    Returns:\n",
    "        np.ndarray: The modified image with DEM data.\n",
    "    \"\"\"\n",
    "    modified_image = image.copy().astype(np.float32)\n",
    "    modified_image[:, :, channel] = dem_data / 4000.0  # Reduce the DEM data in the 0-1 range\n",
    "    return modified_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to substitute Slope data into the image\n",
    "def substitute_slope(image, dem_data, channel=2):\n",
    "    \"\"\"\n",
    "    Substitute one of the layers of the image with the Slope data.\n",
    "    Args:\n",
    "        image (np.ndarray): The original image.\n",
    "        dem_data (np.ndarray): The DEM data.\n",
    "        channel (int): The channel to be replaced with Slope data.\n",
    "    Returns:\n",
    "        np.ndarray: The modified image with Slope data.\n",
    "    \"\"\"\n",
    "    slope = calculate_slope(dem_data / 4000.0)\n",
    "    modified_image = image.copy().astype(np.float32)\n",
    "    modified_image[:, :, channel] = slope\n",
    "    return modified_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id(path):\n",
    "    # Normalize path separators\n",
    "    path = path.replace(\"\\\\\", \"/\")\n",
    "    # Get the filename without extension\n",
    "    filename = os.path.basename(path)\n",
    "    id_, _ = os.path.splitext(filename)\n",
    "    # Remove the trailing \"_rcs\" if present\n",
    "    if id_.endswith(\"_rcs\"):\n",
    "        id_ = id_[:-4]\n",
    "    return id_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data in batches\n",
    "def process_in_batches(dem_rcs_paths, batch_size=100):\n",
    "    for i in range(0, len(dem_rcs_paths), batch_size):\n",
    "\n",
    "        # Get the batch\n",
    "        batch_paths = dem_rcs_paths[i:i + batch_size]\n",
    "        dataset_dict = {\n",
    "                \"image\": [],\n",
    "                \"label\": [],\n",
    "                \"box\": []\n",
    "            }\n",
    "        \n",
    "        for dem_path, rcs_path in batch_paths:\n",
    "\n",
    "            with rasterio.open(dem_path) as src:\n",
    "                    dem = src.read(1)\n",
    "            \n",
    "            image = cv2.resize(substitute_dem(rcs._merge_to_rgb_all(*rcs.read_rcs_image(rcs_path))[0], dem), (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "            pmd = PMD_features([32, 64, 128, 256])\n",
    "            image_ori = rcs._merge_to_rgb_all(*rcs.read_rcs_image(rcs_path))[0]\n",
    "            image_tensor = torch.from_numpy(np.array(image_ori)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "            output = pmd(image_tensor)\n",
    "            output_np = output.cpu().detach().numpy().squeeze().transpose(1, 2, 0)  # adjust transpose if necessary\n",
    "            label = cv2.resize(substitute_slope(output_np, dem), (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "            pmd = PMD_features([32, 64, 128, 256])\n",
    "            \n",
    "            \n",
    "            dataset_dict[\"image\"].append(image)\n",
    "            dataset_dict[\"label\"].append(label) \n",
    "            dataset_dict[\"box\"].append([0, 0, 512, 512])  # The box is the entire image \n",
    "\n",
    "        dataset = Dataset.from_dict(dataset_dict)\n",
    "        dataset.save_to_disk('datasetBoxes' + str(i))\n",
    "        # Clear memory\n",
    "        del dataset_dict, dataset\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTest = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process data in batches\n",
    "def process_in_batches(dem_rcs_paths, batch_size=100):\n",
    "    for i in range(0, len(dem_rcs_paths), batch_size):\n",
    "\n",
    "        # Get the batch\n",
    "        batch_paths = dem_rcs_paths[i:i + batch_size]\n",
    "        dataset_dict = {\n",
    "            \"VH0\": [],\n",
    "            \"VH1\": [],\n",
    "            \"VV0\": [],\n",
    "            \"VV1\": [],\n",
    "            \"dem\": [],\n",
    "            \"label\": [],\n",
    "            \"box\": [],\n",
    "            \"slope\": [],\n",
    "            \"id\": []\n",
    "        }\n",
    "        \n",
    "        for dem_path, rcs_path in batch_paths:\n",
    "\n",
    "            with rasterio.open(dem_path) as src:\n",
    "                    dem = src.read(1)\n",
    "            \n",
    "            image = rcs._merge_all(*rcs.read_rcs_image(rcs_path))[0]\n",
    "            \n",
    "            \n",
    "            dataset_dict[\"VH0\"].append(cv2.resize(image[:, :, 0], (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"VH1\"].append(cv2.resize(image[:, :, 1], (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"VV0\"].append(cv2.resize(image[:, :, 2], (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"VV1\"].append(cv2.resize(image[:, :, 3], (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"dem\"].append(cv2.resize(dem / 4000.0, (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"slope\"].append(cv2.resize(calculate_slope(dem) / 90, (512, 512), interpolation=cv2.INTER_LINEAR))\n",
    "            dataset_dict[\"box\"].append([0, 0, 512, 512])  # The box is the entire image \n",
    "            dataset_dict[\"id\"].append(extract_id(rcs_path))\n",
    "            dummy_label = np.zeros((512, 512), dtype=np.float32)\n",
    "            dataset_dict[\"label\"].append(dummy_label)\n",
    "\n",
    "        dataset = Dataset.from_dict(dataset_dict)\n",
    "        # Save the dataset to disk\n",
    "        dataset.save_to_disk('datasetBoxes' + str(i))\n",
    "    \n",
    "        # Clear memory\n",
    "        del dataset_dict, dataset\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_in_batches(dem_rcs_paths, batch_size= len(rcs_paths)//divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dem_rcs_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_dataset_loaded_and_not_empty(dataset):\n",
    "    \"\"\"\n",
    "    Check if the dataset is loaded and not empty.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (Dataset): The loaded dataset.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the dataset is loaded and not empty, False otherwise.\n",
    "    \"\"\"\n",
    "    if dataset is None:\n",
    "        return False\n",
    "    if len(dataset) == 0:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetsNames = ['datasetBoxes' + str(i) for i in range(0, len(dem_rcs_paths), len(dem_rcs_paths)//divide)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Half of the datasets\n",
    "datasetsNames = datasetsNames[len(datasetsNames)//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetList = []\n",
    "for datasetName in datasetsNames:\n",
    "    dataset = load_from_disk(datasetName)\n",
    "    if is_dataset_loaded_and_not_empty(dataset):\n",
    "        print(f\"Dataset '{datasetName}' loaded successfully.\")\n",
    "    datasetList.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "# Concatenate the datasets\n",
    "merged_dataset = concatenate_datasets(datasetList)\n",
    "# Save the dataset to disk\n",
    "#merged_dataset.save_to_disk('datasetSelfSupDEMFloat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk('datasetSelfSupDEMFloat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and test sets (90% training, 10% test)\n",
    "train_test_split_ratio = 0.9\n",
    "train_dataset, test_dataset = dataset.train_test_split(test_size=1 - train_test_split_ratio, seed = 20).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training dataset into training and validation sets (90% training, 10% validation)\n",
    "train_val_split_ratio = 0.9\n",
    "train_dataset, val_dataset = train_dataset.train_test_split(test_size=1 - train_val_split_ratio, seed = 20).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset.shape)\n",
    "print(val_dataset.shape)\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset.save_to_disk('datasetTrainSelfSupFinal')\n",
    "val_dataset.save_to_disk('datasetValSelfSupSlopeFinal')\n",
    "test_dataset.save_to_disk('datasetTestSelfSupSlopeFinal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add this as a new cell in your notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of samples you want to visualize\n",
    "n_samples = 5\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    sample = dataset[idx]  # Assuming 'dataset' contains your merged dataset\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    \n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display the image (convert to uint8 if necessary)\n",
    "    axes[0].imshow(image)\n",
    "    axes[0].set_title(\"Image\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Display the label (using grayscale)\n",
    "    axes[1].imshow(label)\n",
    "    axes[1].set_title(\"Label(Denoising Kernels and Slope)\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the number of samples you want to visualize\n",
    "n_samples = 5\n",
    "\n",
    "for idx in range(n_samples):\n",
    "    sample = dataset[idx]\n",
    "    image = sample['image']\n",
    "    label = sample['label']\n",
    "    \n",
    "    # Convert to numpy arrays if necessary\n",
    "    if isinstance(image, list):\n",
    "        image = np.array(image)\n",
    "    if isinstance(label, list):\n",
    "        label = np.array(label)\n",
    "    \n",
    "    # Extract the third channel, assuming images are in HWC format\n",
    "    image_third = image[:, :, 2]\n",
    "    label_third = label[:, :, 2]\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Display the third channel from the image and label\n",
    "    axes[0].imshow(image_third, cmap='gray')\n",
    "    axes[0].set_title(\"Image - Third Channel\")\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(label_third, cmap='gray')\n",
    "    axes[1].set_title(\"Label - Third Channel\")\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
