{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import gc\n",
    "\n",
    "from datasets import Dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the path of the script\n",
    "current_file = Path(__file__).resolve() # src/training/your_script.py\n",
    "\n",
    "# 2. Go up one level to 'src', then into 'config'\n",
    "config_path = current_file.parent.parent / \"config\" / \"config_general.yaml\"\n",
    "\n",
    "# 3. Load the YAML\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. Resolve the root of the project (one level above 'src')\n",
    "# This ensures that \"./data\" in the YAML is interpreted relative to the Project_Root\n",
    "PROJECT_ROOT = current_file.parent.parent.parent\n",
    "os.chdir(PROJECT_ROOT) \n",
    "\n",
    "# Extract paths from YAML\n",
    "DATA_DIR = config['paths']['data']\n",
    "CHECKPOINT_DIR = config['paths']['checkpoints']\n",
    "SAM_CHECKPOINT = config['paths']['sam_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_from_disk(os.path.join(DATA_DIR, 'datasetTestFinal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple ids in idx\n",
    "idx = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train_dataset[idx]\n",
    "ground_truth_mask = np.array(item[\"label\"])\n",
    "VH0 = np.array(item[\"VH0\"])\n",
    "VH1 = np.array(item[\"VH1\"])\n",
    "VV0 = np.array(item[\"VV0\"])\n",
    "VV1 = np.array(item[\"VV1\"])\n",
    "dem = np.array(item[\"dem\"])\n",
    "slope = np.array(item[\"slope\"])\n",
    "\n",
    "#Combine all channels to create image\n",
    "image = np.stack([VH0, VH1, VV0, VV1, dem, slope], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.shape)\n",
    "print(ground_truth_mask.shape)\n",
    "print(VH0.shape)\n",
    "print(VH1.shape)\n",
    "print(VV0.shape)\n",
    "print(VV1.shape)\n",
    "print(dem.shape)\n",
    "print(slope.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#draw parts of a single image\n",
    "\n",
    "singleimage = image[2, :, :, :]\n",
    "\n",
    "# Plot each channel of the single image\n",
    "fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
    "axs[0].imshow(singleimage[0, :, :], cmap='gray')\n",
    "axs[0].set_title('VH0')\n",
    "axs[1].imshow(singleimage[1, :, :], cmap='gray')\n",
    "axs[1].set_title('VH1')\n",
    "axs[2].imshow(singleimage[2, :, :], cmap='gray')\n",
    "axs[2].set_title('VV0')\n",
    "axs[3].imshow(singleimage[3, :, :], cmap='gray')\n",
    "axs[3].set_title('VV1')\n",
    "axs[4].imshow(singleimage[4, :, :], cmap='gray')\n",
    "axs[4].set_title('DEM')\n",
    "axs[5].imshow(singleimage[5, :, :], cmap='gray')\n",
    "axs[5].set_title('Slope')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bounding box prompt\n",
    "# tried -5 5, -5 15, -5 10\n",
    "prompt = item[\"box\"]\n",
    "xchange = np.random.randint(-5, 5)\n",
    "ychange = np.random.randint(-5, 5)\n",
    "wchange = np.random.randint(-5, 5) \n",
    "hchange = np.random.randint(-5, 5) \n",
    "input_boxes = []\n",
    "for box in prompt: \n",
    "    x, y, w, h = box\n",
    "    input_boxes.append([[max(0, x - xchange), max(0, y - ychange), min(512, x + w + wchange), min(512, y + h + hchange)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SamProcessor\n",
    "\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image and prompt for the model\n",
    "inputs = processor(image[:,0:3,:,:], input_boxes=input_boxes, do_normalize=False, return_tensors=\"pt\", do_rescale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "image_tensor = torch.tensor(image, dtype=torch.float32)\n",
    "# Assuming `image_tensor` has shape (batch, 6, 512, 512)\n",
    "image_resized = F.interpolate(image_tensor, size=(1024, 1024), mode='bilinear', align_corners=False)\n",
    "print(image_resized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singleimage = image_resized[2, :, :, :]\n",
    "\n",
    "# Plot each channel of the single image\n",
    "fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
    "axs[0].imshow(singleimage[0, :, :], cmap='gray')\n",
    "axs[0].set_title('VH0')\n",
    "axs[1].imshow(singleimage[1, :, :], cmap='gray')\n",
    "axs[1].set_title('VH1')\n",
    "axs[2].imshow(singleimage[2, :, :], cmap='gray')\n",
    "axs[2].set_title('VV0')\n",
    "axs[3].imshow(singleimage[3, :, :], cmap='gray')\n",
    "axs[3].set_title('VV1')\n",
    "axs[4].imshow(singleimage[4, :, :], cmap='gray')\n",
    "axs[4].set_title('DEM')\n",
    "axs[5].imshow(singleimage[5, :, :], cmap='gray')\n",
    "axs[5].set_title('Slope')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "singleimage = image[2, :, :, :]\n",
    "\n",
    "# Plot each channel of the single image\n",
    "fig, axs = plt.subplots(1, 6, figsize=(15, 5))\n",
    "axs[0].imshow(singleimage[0, :, :], cmap='gray')\n",
    "axs[0].set_title('VH0')\n",
    "axs[1].imshow(singleimage[1, :, :], cmap='gray')\n",
    "axs[1].set_title('VH1')\n",
    "axs[2].imshow(singleimage[2, :, :], cmap='gray')\n",
    "axs[2].set_title('VV0')\n",
    "axs[3].imshow(singleimage[3, :, :], cmap='gray')\n",
    "axs[3].set_title('VV1')\n",
    "axs[4].imshow(singleimage[4, :, :], cmap='gray')\n",
    "axs[4].set_title('DEM')\n",
    "axs[5].imshow(singleimage[5, :, :], cmap='gray')\n",
    "axs[5].set_title('Slope')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# get bounding box prompt\n",
    "# tried -5 5, -5 15, -5 10\n",
    "prompt = item[\"box\"]\n",
    "xchange = np.random.randint(-5, 5)\n",
    "ychange = np.random.randint(-5, 5)\n",
    "wchange = np.random.randint(-5, 5)\n",
    "hchange = np.random.randint(-5, 5)\n",
    "input_boxes = []\n",
    "for box in prompt: \n",
    "    x, y, w, h = box\n",
    "    input_boxes.append([[max(0, x - xchange), max(0, y - ychange), min(512, x + w + wchange), min(512, y + h + hchange)]])\n",
    "\n",
    "boxes_tensor = torch.tensor(input_boxes, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boxes_tensor.shape)\n",
    "boxes_tensor2 = (boxes_tensor * 2).squeeze(1) \n",
    "print(boxes_tensor2.shape)\n",
    "print(boxes_tensor2)\n",
    "print(boxes_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fileter for full image bboxes only\n",
    "full_image_indices = []\n",
    "for i in range(len(train_dataset)):\n",
    "    box = train_dataset[i]['box']\n",
    "    if box == [0, 0, 512, 512]:\n",
    "        full_image_indices.append(i)\n",
    "train_dataset = train_dataset.select(full_image_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from dataprocessing.rcsHandlingFunctions import _rescale\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "item = train_dataset[22]\n",
    "ground_truth_mask = np.array(item[\"label\"])\n",
    "VH0 = np.array(item[\"VH0\"])\n",
    "VH1 = np.array(item[\"VH1\"])\n",
    "VV0 = np.array(item[\"VV0\"])\n",
    "VV1 = np.array(item[\"VV1\"])\n",
    "dem = np.array(item[\"dem\"])\n",
    "slope = np.array(item[\"slope\"])\n",
    "\n",
    "VV = np.stack([VV0, VV1, dem], axis=2)\n",
    "VH = np.stack([VH0, VH1, dem], axis=2)\n",
    "    \n",
    "a = _rescale(VH1 - VH0, 0, .25)\n",
    "\n",
    "b = _rescale(VV1 - VV0, 0, .25)\n",
    "\n",
    "w = _rescale(a - b, 0, 1)\n",
    "\n",
    "r = w*VH0 + (1 - w)*VV0\n",
    "\n",
    "g = w*VH1 + (1 - w)*VV1\n",
    "\n",
    "combVVVH = np.stack([r, g, dem], axis=2)\n",
    "\n",
    "standComb = np.stack([r, g, r], axis=2)\n",
    "\n",
    "difference = np.stack([VV1 - VV0, VH1 - VH0, dem], axis=2)\n",
    "\n",
    "# Set a global title size for all subplots\n",
    "plt.rcParams['axes.titlesize'] = 25\n",
    "# Plot each channel of the single image\n",
    "fig, axs = plt.subplots(2, 3, figsize=(24, 16))\n",
    "\n",
    "\n",
    "axs[0, 0].imshow(standComb)\n",
    "axs[0, 0].set_title('Standard for Manual')\n",
    "\n",
    "axs[0, 1].imshow(combVVVH)\n",
    "axs[0, 1].set_title('Vertical/Horizontal Combination + DEM')\n",
    "\n",
    "axs[0, 2].imshow(difference)\n",
    "axs[0, 2].set_title('Difference of Polarizations + DEM')\n",
    "\n",
    "axs[1, 0].imshow(VV)\n",
    "axs[1, 0].set_title('Vertical Polarization + DEM')\n",
    "\n",
    "axs[1, 1].imshow(VH)\n",
    "axs[1, 1].set_title('Horizontal Polarization + DEM')\n",
    "\n",
    "axs[1, 2].imshow(ground_truth_mask, cmap='gray')\n",
    "axs[1, 2].set_title('Ground Truth Mask')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train_dataset[22]\n",
    "ground_truth_mask = np.array(item[\"label\"])\n",
    "VH0 = np.array(item[\"VH0\"])\n",
    "VH1 = np.array(item[\"VH1\"])\n",
    "VV0 = np.array(item[\"VV0\"])\n",
    "VV1 = np.array(item[\"VV1\"])\n",
    "dem = np.array(item[\"dem\"])\n",
    "slope = np.array(item[\"slope\"])\n",
    "\n",
    "VV = np.stack([VV0, VV1, dem], axis=2)\n",
    "VH = np.stack([VH0, VH1, dem], axis=2)\n",
    "    \n",
    "a = _rescale(VH1 - VH0, 0, .25)\n",
    "\n",
    "b = _rescale(VV1 - VV0, 0, .25)\n",
    "\n",
    "w = _rescale(a - b, 0, 1)\n",
    "\n",
    "r = w*VH0 + (1 - w)*VV0\n",
    "\n",
    "g = w*VH1 + (1 - w)*VV1\n",
    "\n",
    "combVVVH = np.stack([r, g, dem], axis=2)\n",
    "\n",
    "standComb = np.stack([r, g, r], axis=2)\n",
    "\n",
    "difference = np.stack([VV1 - VV0, VH1 - VH0, dem], axis=2)\n",
    "\n",
    "# Set a global title size for all subplots\n",
    "plt.rcParams['axes.titlesize'] = 25\n",
    "# Plot each channel of the single image\n",
    "fig, axs = plt.subplots(1, 4, figsize=(24, 16))\n",
    "\n",
    "axs[0].imshow(combVVVH)\n",
    "axs[0].set_title('V/H Combination + DEM')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(difference)\n",
    "axs[1].set_title('Difference of Polarizations + DEM')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(VV)\n",
    "axs[2].set_title('Vertical Polarization + DEM')\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(VH)\n",
    "axs[3].set_title('Horizontal Polarization + DEM')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(difference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
