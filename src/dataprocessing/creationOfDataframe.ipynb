{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import rasterio\n",
    "import sys\n",
    "import dataprocessing.rcsHandlingFunctions as rcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the path of the script\n",
    "current_file = Path(__file__).resolve() # src/training/your_script.py\n",
    "\n",
    "# 2. Go up one level to 'src', then into 'config'\n",
    "config_path = current_file.parent.parent / \"config\" / \"config_general.yaml\"\n",
    "\n",
    "# 3. Load the YAML\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. Resolve the root of the project (one level above 'src')\n",
    "# This ensures that \"./data\" in the YAML is interpreted relative to the Project_Root\n",
    "PROJECT_ROOT = current_file.parent.parent.parent\n",
    "os.chdir(PROJECT_ROOT) \n",
    "\n",
    "# Extract paths from YAML\n",
    "DATA_DIR = config['paths']['data']\n",
    "CHECKPOINT_DIR = config['paths']['checkpoints']\n",
    "SAM_CHECKPOINT = config['paths']['sam_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(dem_file, print_info=True):\n",
    "    with rasterio.open(dem_file) as src:\n",
    "        # Access metadata\n",
    "        metadata = src.meta\n",
    "        width = src.width\n",
    "        height = src.height\n",
    "        crs = src.crs\n",
    "        bounds = src.bounds\n",
    "        transform = src.transform\n",
    "\n",
    "    # Print the information\n",
    "    print(\"Metadata:\", metadata)\n",
    "    print(\"Width:\", width)\n",
    "    print(\"Height:\", height)\n",
    "    print(\"CRS:\", crs)\n",
    "    print(\"Bounds:\", bounds)\n",
    "    print(\"Transform:\", transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dem_rgb(dem_data):\n",
    "    if len(dem_data.shape) == 2:\n",
    "        dem_data = np.expand_dims(dem_data, axis=-1)\n",
    "    else:\n",
    "        raise ValueError(\"DEM data should have 2 dimensions\")\n",
    "        return None \n",
    "    if dem_data.shape[-1] == 1:\n",
    "        dem_data_rgb = np.repeat(dem_data, 3, axis=-1)\n",
    "    return dem_data_rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#'.jpg', '.jpeg', '.png', '.tif'\n",
    "def get_all_image_paths(root_dir, extensions=['rgb.tif']):\n",
    "    image_paths = []\n",
    "    for subdir, _, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if any(file.lower().endswith(ext) for ext in extensions):\n",
    "                image_paths.append(os.path.join(subdir, file))\n",
    "    return image_paths\n",
    "\n",
    "def read_images(image_paths):\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "        if img is not None:\n",
    "            images.append((path, img))\n",
    "    return images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_all_black(image):\n",
    "    return np.all(image == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_elements_with_substring(strings, substring):\n",
    "    return [s for s in strings if substring in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images with dem and masks: 5132\n",
      "('D:/Users/D4RKR/Documents/GitHub/AvalancheSegmentationWithSam/data/avalanche_input\\\\005C0B2D-985B-4EE9-9DFC-3101AEA5A4C4\\\\005C0B2D-985B-4EE9-9DFC-3101AEA5A4C4_rgb.tif', 'D:/Users/D4RKR/Documents/GitHub/AvalancheSegmentationWithSam/data/avalanche_input\\\\005C0B2D-985B-4EE9-9DFC-3101AEA5A4C4\\\\005C0B2D-985B-4EE9-9DFC-3101AEA5A4C4_dem.tif', 'D:/Users/D4RKR/Documents/GitHub/AvalancheSegmentationWithSam/data/avalanche_masks\\\\005C0B2D-985B-4EE9-9DFC-3101AEA5A4C4_mask.png')\n"
     ]
    }
   ],
   "source": [
    "# Path to the root directory containing nested folders with masks\n",
    "mask_root_dir = DATA_DIR + '/masks/'\n",
    "\n",
    "# Get all masks paths \n",
    "mask_paths = get_all_image_paths(mask_root_dir, ['mask.png'])\n",
    "\n",
    "\n",
    "# Path to the root directory containing nested folders with dem_images and images\n",
    "root_dir = DATA_DIR + '/images/'\n",
    "\n",
    "# Get all dem paths\n",
    "dem_paths = get_all_image_paths(root_dir, ['dem.tif'])\n",
    "\n",
    "# Get all image paths\n",
    "image_paths = get_all_image_paths(root_dir)\n",
    "\n",
    "img_dem_paths = zip(image_paths, dem_paths)\n",
    "img_dem_masks_paths= []\n",
    "for img_path, dem_path in img_dem_paths:\n",
    "    basename = os.path.basename(img_path)\n",
    "    basename = basename.replace('rgb.tif','')\n",
    "    mask_path = find_elements_with_substring(mask_paths, basename)\n",
    "    if(len(mask_path) == 1):\n",
    "        img_dem_masks_paths.append((img_path, dem_path, mask_path[0]))\n",
    "    else:\n",
    "        img_dem_masks_paths.append((img_path, dem_path, None))\n",
    "        #print(f\"Mask not found for image {basename}\")\n",
    "\n",
    "print(f\"Total images with dem and masks: {len(img_dem_masks_paths)}\")\n",
    "print(img_dem_masks_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find bounding boxes for each group of disconnected white pixels\n",
    "def find_bounding_boxes(mask):\n",
    "    # Convert the mask to binary (assuming white pixels are 255 and black pixels are 0)\n",
    "    _, binary_mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    H, W = mask.shape\n",
    "    \n",
    "    # Compute bounding boxes for each contour\n",
    "    bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "\n",
    "    return bounding_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if two bounding boxes intersect\n",
    "def do_boxes_intersect(box1, box2):\n",
    "    x1_min, y1_min, w1, h1 = box1\n",
    "    x1_max, y1_max = x1_min + w1, y1_min + h1\n",
    "    x2_min, y2_min, w2, h2 = box2\n",
    "    x2_max, y2_max = x2_min + w2, y2_min + h2\n",
    "    \n",
    "    # Check if there is an overlap\n",
    "    if x1_min < x2_max and x1_max > x2_min and y1_min < y2_max and y1_max > y2_min:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge two bounding boxes\n",
    "def merge_boxes(box1, box2):\n",
    "    x1_min, y1_min, w1, h1 = box1\n",
    "    x1_max, y1_max = x1_min + w1, y1_min + h1\n",
    "    x2_min, y2_min, w2, h2 = box2\n",
    "    x2_max, y2_max = x2_min + w2, y2_min + h2\n",
    "    \n",
    "    # Find the coordinates of the merged bounding box\n",
    "    x_min = min(x1_min, x2_min)\n",
    "    y_min = min(y1_min, y2_min)\n",
    "    x_max = max(x1_max, x2_max)\n",
    "    y_max = max(y1_max, y2_max)\n",
    "    \n",
    "    # Compute the width and height of the merged bounding box\n",
    "    w = x_max - x_min\n",
    "    h = y_max - y_min\n",
    "    \n",
    "    return (x_min, y_min, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlapping bounding boxes and merge them\n",
    "def merge_overlapping_boxes(bounding_boxes):\n",
    "    merged_boxes = []\n",
    "    while bounding_boxes:\n",
    "        box = bounding_boxes.pop(0)\n",
    "        i = 0\n",
    "        while i < len(bounding_boxes):\n",
    "            if do_boxes_intersect(box, bounding_boxes[i]):\n",
    "                box = merge_boxes(box, bounding_boxes.pop(i))\n",
    "            else:\n",
    "                i += 1\n",
    "        merged_boxes.append(box)\n",
    "    return merged_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_bounds(bounding_boxes, H, W, increase_by=20):\n",
    "    # Increase the bounding box size by 20 pixels in all directions\n",
    "\n",
    "    expanded_bounding_boxes = []\n",
    "    for (x, y, w, h) in bounding_boxes:\n",
    "        x_min = max(0, x - np.random.randint(0, increase_by))\n",
    "        y_min = max(0, y - np.random.randint(0, increase_by))\n",
    "        x_max = min(W, x + w + np.random.randint(0, increase_by))\n",
    "        y_max = min(H, y + h + np.random.randint(0, increase_by))\n",
    "        expanded_bounding_boxes.append((x_min, y_min, x_max - x_min, y_max - y_min))\n",
    "    return expanded_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bounding_boxes(mask, increase_by=20):\n",
    "    H, W = mask.shape\n",
    "    bounding_boxes = find_bounding_boxes(mask)\n",
    "    expanded_bounding_boxes = increase_bounds(bounding_boxes, H, W, increase_by=increase_by)\n",
    "    num_of_boxes = len(expanded_bounding_boxes)\n",
    "    while(True):\n",
    "        expanded_bounding_boxes = merge_overlapping_boxes(expanded_bounding_boxes)\n",
    "        if (num_of_boxes == len(expanded_bounding_boxes)):\n",
    "            break\n",
    "        else:\n",
    "            num_of_boxes = len(expanded_bounding_boxes)\n",
    "    return expanded_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images_dem_masks_resize(img_dem_masks_paths):\n",
    "    data = []\n",
    "    for img_path, dem_path, mask_path in img_dem_masks_paths:\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
    "        # Resize the image\n",
    "        img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "        with rasterio.open(dem_path) as src:\n",
    "            dem_data = src.read(1)\n",
    "            dem_data = cv2.resize(dem_data, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        rcs_path = img_path.replace('rgb.tif', 'rcs.tif')\n",
    "        rcs_data = rcs.read_rcs_image(rcs_path)\n",
    "        if mask is not None:\n",
    "            # Resize the mask\n",
    "            mask = cv2.resize(mask, (512, 512), interpolation=cv2.INTER_NEAREST)\n",
    "            data.append({'image_path': img_path,\n",
    "                         'image': img, \n",
    "                         'mask_path': mask_path, \n",
    "                         'mask': mask, \n",
    "                         'dem_path': dem_path, \n",
    "                         'dem': dem_data,\n",
    "                         'empty_mask': is_all_black(mask), \n",
    "                         'no_mask': False,\n",
    "                         'boxes': create_bounding_boxes(mask),\n",
    "                         'rcs': rcs_data})\n",
    "        else:\n",
    "            data.append({'image_path': img_path,\n",
    "                         'image': img, \n",
    "                         'mask_path': mask_path, \n",
    "                         'mask': mask, \n",
    "                         'dem_path': dem_path, \n",
    "                         'dem': dem_data,\n",
    "                         'empty_mask': True, \n",
    "                         'no_mask': True,\n",
    "                         'boxes': None,\n",
    "                         'rcs': rcs_data})\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_images_dem_masks_resize(img_dem_masks_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images with dem and masks: 5132\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total images with dem and masks: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a file (optional)\n",
    "df.to_pickle('dataframe_avalanches.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
