{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30572879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "def lee_filter(img, size, channel=0):\n",
    "    img_mean = uniform_filter(img[:,:,channel], (size, size))\n",
    "    img_sqr_mean = uniform_filter(img[:,:,channel]**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img[:,:,channel])\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img[:,:,channel] - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3623957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_from_disk\n",
    "import pytorch_lightning as pl\n",
    "import sys\n",
    "import os\n",
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "from model.adapterModel import LitSamModel\n",
    "from utils.statistics import calculate_correlation\n",
    "from model.samDataset import SAMDataset3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e355ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Get the path of the script\n",
    "current_file = Path(__file__).resolve() # src/training/your_script.py\n",
    "\n",
    "# 2. Go up one level to 'src', then into 'config'\n",
    "config_path = current_file.parent.parent / \"config\" / \"config_general.yaml\"\n",
    "\n",
    "# 3. Load the YAML\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 4. Resolve the root of the project (one level above 'src')\n",
    "# This ensures that \"./data\" in the YAML is interpreted relative to the Project_Root\n",
    "PROJECT_ROOT = current_file.parent.parent.parent\n",
    "os.chdir(PROJECT_ROOT) \n",
    "\n",
    "# Extract paths from YAML\n",
    "DATA_DIR = config['paths']['data']\n",
    "CHECKPOINT_DIR = config['paths']['checkpoints']\n",
    "SAM_CHECKPOINT = config['paths']['sam_checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "test_dataset = load_from_disk(os.path,join(DATA_DIR,'datasetTestFinal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75afd2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_dataset[0]['image']\n",
    "test_image = np.array(test_image)\n",
    "print(test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataprocessing.rcsHandlingFunctions import _rescale\n",
    "\n",
    "def create_image(dataset, index):\n",
    "    item = dataset[index]\n",
    "    VH0 = np.array(item[\"VH0\"])\n",
    "    VH1 = np.array(item[\"VH1\"])\n",
    "    VV0 = np.array(item[\"VV0\"])\n",
    "    VV1 = np.array(item[\"VV1\"])\n",
    "    dem = np.array(item[\"dem\"])\n",
    "    slope = np.array(item[\"slope\"])\n",
    "\n",
    "    a = _rescale(VH1 - VH0, 0, .25)\n",
    "\n",
    "    b = _rescale(VV1 - VV0, 0, .25)\n",
    "\n",
    "    w = _rescale(a - b, 0, 1)\n",
    "\n",
    "    r = w*VH0 + (1 - w)*VV0\n",
    "\n",
    "    g = w*VH1 + (1 - w)*VV1\n",
    "\n",
    "    image = np.stack([r, g, dem], axis=2)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = create_image(test_dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d164e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the image\n",
    "test_image = np.asarray(test_image).astype(np.float32)\n",
    "plt.imshow(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9893b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lee filter to the image\n",
    "test_image = test_dataset[1]['image']\n",
    "test_image = np.array(test_image)\n",
    "test_image_filtered = np.zeros_like(test_image)\n",
    "test_image_filtered[:,:,0] = lee_filter(test_image, 3, channel=0)\n",
    "test_image_filtered[:,:,1] = lee_filter(test_image, 3, channel=1)\n",
    "test_image_filtered[:,:,2] = test_image[:,:,2]  # Assuming the third channel is not filtered\n",
    "\n",
    "\n",
    "#visualize the images in a grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(test_image_filtered)\n",
    "axs[1].set_title('Filtered Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd14537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lee filter to the image\n",
    "test_image = test_dataset[1]['image']\n",
    "test_image = np.array(test_image)\n",
    "test_image_filtered = np.zeros_like(test_image)\n",
    "test_image_averaged = np.zeros_like(test_image)\n",
    "test_image_averaged[:,:,0] = (test_image[:,:,0] + test_image[:,:,1]) / 2  # Mix the first two layers\n",
    "test_image_averaged[:,:,1] = (test_image[:,:,0] + test_image[:,:,1]) / 2  # Mix the first two layers\n",
    "test_image_averaged[:,:,2] = test_image[:,:,2]  # Assuming the third channel is not filtered\n",
    "test_image_filtered[:,:,0] = lee_filter(test_image_averaged, 3, channel=0)\n",
    "test_image_filtered[:,:,1] = lee_filter(test_image_averaged, 3, channel=1)\n",
    "test_image_filtered[:,:,2] = test_image_averaged[:,:,2]  # Assuming the third channel is not filtered\n",
    "\n",
    "\n",
    "#visualize the images in a grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(test_image_filtered)\n",
    "axs[1].set_title('Filtered Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bc0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_filter_2(img, size, num_looks = 100, channel=0):\n",
    "    \"\"\"\n",
    "    Correctly applies the Lee filter to a SAR image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): The input image (should be intensity data).\n",
    "        size (int): The size of the sliding window.\n",
    "        num_looks (float): The number of looks, used to estimate noise variance.\n",
    "        channel (int): The channel to process if the image is multi-channel.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The filtered image.\n",
    "    \"\"\"\n",
    "    # Extract the specified channel and convert to float for processing\n",
    "    img_channel = img[:, :, channel]\n",
    "    \n",
    "    # Calculate local mean and variance using a sliding window\n",
    "    img_mean = uniform_filter(img_channel, size=size)\n",
    "    img_sqr_mean = uniform_filter(img_channel**2, size=size)\n",
    "    local_variance = img_sqr_mean - img_mean**2\n",
    "    \n",
    "    # --- The key correction is here ---\n",
    "    # We estimate the noise variance based on the number of looks (L).\n",
    "    # The coefficient of variation (Cu) for multi-look intensity data is 1 / sqrt(L).\n",
    "    # Noise variance is local_mean^2 * Cu^2.\n",
    "    cu = 1.0 / np.sqrt(num_looks)\n",
    "    noise_variance = img_mean**2 * cu**2\n",
    "    \n",
    "    # Calculate the adaptive weight 'K'\n",
    "    # The denominator must handle cases where local_variance is close to zero.\n",
    "    K = np.zeros_like(img_channel)\n",
    "    den = local_variance + noise_variance\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    non_zero_den_mask = den > 1e-6\n",
    "    K[non_zero_den_mask] = (local_variance[non_zero_den_mask] - noise_variance[non_zero_den_mask]) / den[non_zero_den_mask]\n",
    "    K[K < 0] = 0 # Ensure weights are not negative\n",
    "    \n",
    "    # Apply the final filter formula\n",
    "    img_output = img_mean + K * (img_channel - img_mean)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7de614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_enl(image_patch):\n",
    "    \"\"\"\n",
    "    Estimates the Equivalent Number of Looks (ENL) from a homogeneous image patch.\n",
    "\n",
    "    Args:\n",
    "        image_patch (np.ndarray): A NumPy array representing a homogeneous area.\n",
    "\n",
    "    Returns:\n",
    "        float: The estimated ENL.\n",
    "    \"\"\"\n",
    "    # Calculate the mean and variance of the patch\n",
    "    patch_mean = np.mean(image_patch)\n",
    "    patch_variance = np.var(image_patch)\n",
    "\n",
    "    # Ensure variance is not zero to avoid division errors\n",
    "    if patch_variance == 0:\n",
    "        return np.inf  # Return infinity if variance is zero\n",
    "    \n",
    "    enl = (patch_mean**2) / patch_variance\n",
    "    return enl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498da6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = test_dataset[1]['image']\n",
    "test_image = np.array(test_image)\n",
    "enl = estimate_enl(test_image)\n",
    "print(f\"Estimated ENL: {enl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956416c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply lee filter to the image\n",
    "num_looks = 200  # Example value for number of looks\n",
    "test_image = test_dataset[1]['image']\n",
    "test_image = np.array(test_image)\n",
    "test_image_filtered = np.zeros_like(test_image)\n",
    "test_image_filtered[:,:,0] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=0)\n",
    "test_image_filtered[:,:,1] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=1)\n",
    "test_image_filtered[:,:,2] = test_image[:,:,2]  # Assuming the third channel is not filtered\n",
    "\n",
    "\n",
    "#visualize the images in a grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(test_image_filtered)\n",
    "#title and num looks\n",
    "axs[1].set_title(f'Filtered Image (Num Looks: {num_looks})')\n",
    "\n",
    "#apply lee filter to the image\n",
    "num_looks = 500  # Example value for number of looks\n",
    "test_image_filtered = np.zeros_like(test_image)\n",
    "test_image_filtered[:,:,0] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=0)\n",
    "test_image_filtered[:,:,1] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=1)\n",
    "test_image_filtered[:,:,2] = test_image[:,:,2]  # Assuming the third channel is not filtered\n",
    "\n",
    "\n",
    "#visualize the images in a grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(test_image_filtered)\n",
    "#title and num looks\n",
    "axs[1].set_title(f'Filtered Image (Num Looks: {num_looks})')\n",
    "\n",
    "#apply lee filter to the image\n",
    "num_looks = 3  # Example value for number of looks\n",
    "test_image_filtered = np.zeros_like(test_image)\n",
    "test_image_filtered[:,:,0] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=0)\n",
    "test_image_filtered[:,:,1] = lee_filter_2(test_image, 5, num_looks= num_looks, channel=1)\n",
    "test_image_filtered[:,:,2] = test_image[:,:,2]  # Assuming the third channel is not filtered\n",
    "\n",
    "\n",
    "#visualize the images in a grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(test_image)\n",
    "axs[0].set_title('Original Image')\n",
    "axs[1].imshow(test_image_filtered)\n",
    "#title and num looks\n",
    "axs[1].set_title(f'Filtered Image (Num Looks: {num_looks})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad818d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lee_filter(img, size, channel=0):\n",
    "    img_mean = uniform_filter(img[:,:,channel], (size, size))\n",
    "    img_sqr_mean = uniform_filter(img[:,:,channel]**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img[:,:,channel])\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img[:,:,channel] - img_mean)\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from the file \n",
    "df_loaded = pd.read_pickle(os.path.join(DATA_DIR, \"test_df_sam.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d47ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcs_list = df_loaded.loc[0, 'rcs']\n",
    "dem = df_loaded.loc[0, 'dem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c4b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the directory containing lit_sam_model.py to the Python path\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "import dataprocessing.rcsHandlingFunctions as rcs\n",
    "\n",
    "print(f\"RCS: {rcs_list.shape}, DEM: {dem.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834e0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1 = rcs_list[0]\n",
    "vv2 = rcs_list[1]\n",
    "vh1 = rcs_list[2]\n",
    "vh2 = rcs_list[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e6aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rcs_reshaped = np.stack(rcs_list, axis=-1)\n",
    "print(rcs_reshaped.shape)  # should output (364, 364, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d0670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enl = estimate_enl(vh2)\n",
    "print(f\"Estimated ENL: {enl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44885304",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_rcs_list = []\n",
    "for i in range(4):\n",
    "    enl = estimate_enl(rcs_reshaped[:,:,i])\n",
    "    filtered_rcs = lee_filter(rcs_reshaped, 5, channel=i)\n",
    "    filterd_rcs_list.append(filtered_rcs)\n",
    "\n",
    "rcs_filtered = np.stack(filterd_rcs_list, axis=-1)\n",
    "print(f\"Filtered RCS shape: {rcs_filtered.shape}\")  # should output (364, 364, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5394983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1 = rcs_list[0]\n",
    "vv1_filterd = rcs_filtered[:, :, 0]\n",
    "\n",
    "vv1_rescaled = rcs.vv1 = rcs._rescale(vv1, -23, -3)\n",
    "vv1_filterd_rescaled = rcs._rescale(vv1_filterd, -23, -3)\n",
    "\n",
    "#visualze the original and filtered RCS\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(vv1_rescaled, cmap='gray')\n",
    "axs[0].set_title('Original VV1 RCS')\n",
    "axs[1].imshow(vv1_filterd_rescaled, cmap='gray')\n",
    "axs[1].set_title('Filtered VV1 RCS')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7249ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv1 = rcs_list[0]\n",
    "vv1_filterd = rcs_filtered[:, :, 0]\n",
    "\n",
    "vv1_rescaled = rcs.vv1 = rcs._rescale(vv1, -23, -3)\n",
    "vv1_filterd_rescaled = rcs._rescale(vv1_filterd, -23, -3)\n",
    "\n",
    "vv2 = rcs_list[1]\n",
    "vv2_filterd = rcs_filtered[:, :, 1]\n",
    "vv2_rescaled = rcs.vv2 = rcs._rescale(vv2, -23, -3)\n",
    "vv2_filterd_rescaled = rcs._rescale(vv2_filterd, -23, -3)\n",
    "\n",
    "image_vv1 = np.stack((vv1_rescaled, vv2_rescaled, vv1_rescaled), axis=-1)\n",
    "image_vv1_filterd = np.stack((vv1_filterd_rescaled, vv2_filterd_rescaled, vv1_filterd_rescaled), axis=-1)\n",
    "\n",
    "#visualize the original and filtered RCS\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].imshow(image_vv1)\n",
    "axs[0].set_title('Original VV RCS')\n",
    "axs[1].imshow(image_vv1_filterd)\n",
    "axs[1].set_title('Filtered VV RCS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacf01b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c727f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Get_gradient_nopadding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Get_gradient_nopadding, self).__init__()\n",
    "        kernel_v = [[0, -1, 0],\n",
    "                    [0, 0, 0],\n",
    "                    [0, 1, 0]]\n",
    "        kernel_h = [[0, 0, 0],\n",
    "                    [-1, 0, 1],\n",
    "                    [0, 0, 0]]\n",
    "        kernel_h = torch.FloatTensor(kernel_h).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_v = torch.FloatTensor(kernel_v).unsqueeze(0).unsqueeze(0)\n",
    "        self.weight_h = nn.Parameter(data=kernel_h, requires_grad=False)\n",
    "        self.weight_v = nn.Parameter(data=kernel_v, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_list = []\n",
    "        for i in range(2):\n",
    "            x_i = x[:, i]\n",
    "            x_i_v = F.conv2d(x_i.unsqueeze(1), self.weight_v, padding=1)\n",
    "            x_i_h = F.conv2d(x_i.unsqueeze(1), self.weight_h, padding=1)\n",
    "            x_i = torch.sqrt(torch.pow(x_i_v, 2) + torch.pow(x_i_h, 2) + 1e-6)\n",
    "            x_list.append(x_i)\n",
    "        x_list.append(x[:, 2].unsqueeze(1))  # Append the third channel without modification\n",
    "\n",
    "        #print(x_list[1]-x_list[0])\n",
    "        x = torch.cat(x_list, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Get_curvature(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Get_curvature, self).__init__()\n",
    "        kernel_v1 = [[0, -1, 0],\n",
    "                     [0, 0, 0],\n",
    "                     [0, 1, 0]]\n",
    "        kernel_h1 = [[0, 0, 0],\n",
    "                     [-1, 0, 1],\n",
    "                     [0, 0, 0]]\n",
    "        kernel_h2 = [[0, 0, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, 0],\n",
    "                     [1, 0, -2, 0, 1],\n",
    "                     [0, 0, 0, 0, 0],\n",
    "                     [0, 0, 0, 0, 0]]\n",
    "        kernel_v2 = [[0, 0, 1, 0, 0],\n",
    "                     [0, 0, 0, 0, 0],\n",
    "                     [0, 0, -2, 0, 0],\n",
    "                     [0, 0, 0, 0, 0],\n",
    "                     [0, 0, 1, 0, 0]]\n",
    "        kernel_w2 = [[1, 0, -1],\n",
    "                     [0, 0, 0],\n",
    "                     [-1, 0, 1]]\n",
    "        kernel_h1 = torch.FloatTensor(kernel_h1).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_v1 = torch.FloatTensor(kernel_v1).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_v2 = torch.FloatTensor(kernel_v2).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_h2 = torch.FloatTensor(kernel_h2).unsqueeze(0).unsqueeze(0)\n",
    "        kernel_w2 = torch.FloatTensor(kernel_w2).unsqueeze(0).unsqueeze(0)\n",
    "        self.weight_h1 = nn.Parameter(data=kernel_h1, requires_grad=False)\n",
    "        self.weight_v1 = nn.Parameter(data=kernel_v1, requires_grad=False)\n",
    "        self.weight_v2 = nn.Parameter(data=kernel_v2, requires_grad=False)\n",
    "        self.weight_h2 = nn.Parameter(data=kernel_h2, requires_grad=False)\n",
    "        self.weight_w2 = nn.Parameter(data=kernel_w2, requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_list = []\n",
    "        for i in range(2):\n",
    "            x_i = x[:, i]\n",
    "            x_i_v = F.conv2d(x_i.unsqueeze(1), self.weight_v1, padding=1)\n",
    "            x_i_h = F.conv2d(x_i.unsqueeze(1), self.weight_h1, padding=1)\n",
    "            x_i_v2 = F.conv2d(x_i.unsqueeze(1), self.weight_v2, padding=2)\n",
    "            x_i_h2 = F.conv2d(x_i.unsqueeze(1), self.weight_h2, padding=2)\n",
    "            x_i_w2 = F.conv2d(x_i.unsqueeze(1), self.weight_w2, padding=1)\n",
    "            x_i = x[:, i]\n",
    "            x_i_v = F.conv2d(x_i.unsqueeze(1), self.weight_v1, padding=1)\n",
    "            x_i_h = F.conv2d(x_i.unsqueeze(1), self.weight_h1, padding=1)\n",
    "            x_i_v2 = F.conv2d(x_i.unsqueeze(1), self.weight_v2, padding=2)\n",
    "            x_i_h2 = F.conv2d(x_i.unsqueeze(1), self.weight_h2, padding=2)\n",
    "            x_i_w2 = F.conv2d(x_i.unsqueeze(1), self.weight_w2, padding=1)\n",
    "            sum = torch.pow((torch.pow(x_i_v, 2) + torch.pow(x_i_h, 2) + 1), 3 / 2)\n",
    "            fh = torch.mul((torch.pow(x_i_v, 2) + 1), x_i_h2) - 2 * torch.mul(torch.mul(x_i_v, x_i_h), x_i_w2) + torch.mul(\n",
    "                (torch.pow(x_i_h, 2) + 1), x_i_v2)\n",
    "            x_i = torch.div(fh, sum + 1e-10)\n",
    "            x_list.append(x_i)\n",
    "            #sum = (torch.pow(x_i_v, 2) + torch.pow(x_i_h, 2)) * 2\n",
    "            #fh = torch.mul(torch.pow(x_i_v, 2), x_i_h2) - 2 * torch.mul(torch.mul(x_i_v, x_i_h), x_i_w2) + torch.mul(\n",
    "            #    torch.pow(x_i_h, 2), x_i_v2)\n",
    "            #x_i = torch.div(torch.abs(fh), sum + 1e-10)\n",
    "            #x_list.append(x_i)\n",
    "            \n",
    "        x_list.append(x[:, 2].unsqueeze(1))  # Append the third channel without modification\n",
    "        x = torch.cat(x_list, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeatureEncoder(nn.Module):\n",
    "    def __init__(self, out_dims):\n",
    "        super(FeatureEncoder, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, out_dims[0], kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_dims[0], out_dims[0], kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(out_dims[0], out_dims[1], kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "        self.conv4 = nn.Conv2d(out_dims[1], out_dims[1], kernel_size=3, padding=1)\n",
    "        self.relu4 = nn.ReLU(inplace=True)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(out_dims[1], out_dims[2], kernel_size=3, padding=1)\n",
    "        self.relu5 = nn.ReLU(inplace=True)\n",
    "        self.conv6 = nn.Conv2d(out_dims[2], out_dims[2], kernel_size=3, padding=1)\n",
    "        self.relu6 = nn.ReLU(inplace=True)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv7 = nn.Conv2d(out_dims[2], out_dims[3], kernel_size=3, padding=1)\n",
    "        self.relu7 = nn.ReLU(inplace=True)\n",
    "        self.conv8 = nn.Conv2d(out_dims[3], out_dims[3], kernel_size=3, padding=1)\n",
    "        self.relu8 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Stage 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x1 = x\n",
    "\n",
    "        # Stage 2\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x2 = x\n",
    "\n",
    "        # Stage 3\n",
    "        x = self.conv5(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.maxpool3(x)\n",
    "        x3 = x\n",
    "\n",
    "        # Stage 4\n",
    "        x = self.conv7(x)\n",
    "        x = self.relu7(x)\n",
    "        x = self.conv8(x)\n",
    "        x = self.relu8(x)\n",
    "        x4 = x\n",
    "\n",
    "        return x1, x2, x3, x4\n",
    "\n",
    "\n",
    "class PMD_features(nn.Module):\n",
    "    def __init__(self, out_dims, gradient = True):\n",
    "        super(PMD_features, self).__init__()\n",
    "        if gradient:\n",
    "            self.PMD_head = Get_gradient_nopadding()\n",
    "        else:\n",
    "            self.PMD_head = Get_curvature()\n",
    "        # self.feature_ext = FeatureEncoder(out_dims)\n",
    "\n",
    "    def forward(self, images):\n",
    "        PMD_images = self.PMD_head(images)\n",
    "        # PMD_feature = self.feature_ext(PMD_images)\n",
    "\n",
    "        return PMD_images\n",
    "\n",
    "\n",
    "# class Adapter(nn.Module):\n",
    "#     def __init__(self, out_dims):\n",
    "#         super(Adapter, self).__init__()\n",
    "#         self.PMD_head = Get_gradient_nopadding()\n",
    "#         self.feature_ext = FeatureEncoder(out_dims)\n",
    "#\n",
    "#     def forward(self, images):\n",
    "#         PMD_images = self.PMD_head(images)\n",
    "#         PMD_feature = self.feature_ext(PMD_images)\n",
    "#\n",
    "#         return PMD_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image = test_dataset[0]['image']\n",
    "image = np.array(image)\n",
    "#show layers indipendently\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(image.shape[2]):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(image[:, :, i], cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pmd = PMD_features([32, 64, 128, 256])\n",
    "image = create_image(test_dataset, 0)\n",
    "image_tensor = torch.from_numpy(np.array(image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "output = pmd(image_tensor)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(output[0].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01451d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pmd = PMD_features([32, 64, 128, 256])\n",
    "image = test_dataset[0]['image']\n",
    "#Mix the first two layers of image before calculating pmd\n",
    "image = np.array(image)\n",
    "image[:,:,0] = (image[:,:,0] + image[:,:,1]) / 2\n",
    "image[:,:,1] = (image[:,:,0] + image[:,:,1]) / 2\n",
    "image_tensor = torch.from_numpy(np.array(image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "output = pmd(image_tensor)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(output[0].permute(1, 2, 0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db550e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pmd = PMD_features([32, 64, 128, 256], gradient=False)\n",
    "image = test_dataset[1]['image']\n",
    "image_tensor = torch.from_numpy(np.array(image)).permute(2, 0, 1).unsqueeze(0).float()\n",
    "output = pmd(image_tensor)\n",
    "# Convert the output tensor to a NumPy array\n",
    "out_np = output[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Apply min-max normalization to scale the values between 0 and 1\n",
    "out_norm = (out_np - out_np.min()) / (out_np.max() - out_np.min())\n",
    "\n",
    "out_norm = output * -1  # Assuming you want to invert the output for visualization\n",
    "out_norm = out_norm[0].permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(output[0].permute(1, 2, 0).cpu())\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image)  # original image\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(out_norm)  # normalized PMD output\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e31a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_speckle_noise_gamma(image, num_looks=1, amplitude=False):\n",
    "    \"\"\"\n",
    "    Adds simulated speckle noise to a SAR image using a Gamma distribution.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): The input SAR image. Can be intensity or amplitude.\n",
    "        num_looks (float): The number of looks used to control the noise level. \n",
    "                           A smaller value (e.g., 1) produces more speckle. \n",
    "                           Must be > 0.\n",
    "        amplitude (bool): Set to True if the input image is in amplitude, \n",
    "                          False if it is in intensity.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The image with added speckle noise.\n",
    "    \"\"\"\n",
    "    if num_looks <= 0:\n",
    "        raise ValueError(\"Number of looks must be greater than 0.\")\n",
    "        \n",
    "    # Get image dimensions\n",
    "    rows, cols = image.shape\n",
    "\n",
    "    # If the input is amplitude, convert it to intensity first.\n",
    "    # The Gamma model for speckle applies to intensity.\n",
    "    if amplitude:\n",
    "        intensity_image = image**2\n",
    "    else:\n",
    "        intensity_image = image\n",
    "\n",
    "    # Generate a noise matrix from a Gamma distribution\n",
    "    # The shape parameter 'k' is the number of looks.\n",
    "    # The scale parameter 'theta' is 1 / k.\n",
    "    # The mean of this distribution is k * (1/k) = 1, which ensures\n",
    "    # the overall image intensity is not biased.\n",
    "    noise = np.random.gamma(shape=num_looks, scale=1.0/num_looks, size=(rows, cols))\n",
    "\n",
    "    # Multiply the intensity image by the noise matrix\n",
    "    noisy_intensity = intensity_image * noise\n",
    "    \n",
    "    # If the original input was amplitude, convert the noisy intensity back\n",
    "    if amplitude:\n",
    "        noisy_image = np.sqrt(noisy_intensity)\n",
    "    else:\n",
    "        noisy_image = noisy_intensity\n",
    "        \n",
    "    return noisy_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a09de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class GF(nn.Module):\n",
    "    def __init__(self, nbins=9, pool=7, kensize=5, img_size=224, patch_size=16):\n",
    "        super(GF, self).__init__()\n",
    "        self.nbins = nbins\n",
    "        self.pool = pool\n",
    "        self.pi = math.pi\n",
    "        self.img_size = img_size\n",
    "        self.patch_size = patch_size\n",
    "        self.k = kensize\n",
    "\n",
    "        # def creat_gauss_kernel(r=1, sigma=-1):\n",
    "        #     if sigma <= 0:\n",
    "        #         sigma = 0.3 * ((2*r+1 - 1) * 0.5 - 1) + 0.8\n",
    "        #\n",
    "        #     X = np.linspace(-r, r, 2*r+1)\n",
    "        #     Y = np.linspace(-r, r, 2*r+1)\n",
    "        #     x, y = np.meshgrid(X, Y)\n",
    "        #     x0 = 0\n",
    "        #     y0 = 0\n",
    "        #     gauss = np.exp(- ((x - x0) ** 2 + (y - y0) ** 2) / (2 * sigma ** 2))\n",
    "        #\n",
    "        #     M_13 = np.concatenate([np.ones([r, 2*r+1]), np.zeros([r+1, 2*r+1])], axis=0)\n",
    "        #     M_23 = np.concatenate([np.zeros([r+1, 2 * r + 1]), np.ones([r, 2 * r + 1])], axis=0)\n",
    "        #\n",
    "        #     M_11 = np.concatenate([np.ones([2*r+1, r]), np.zeros([2*r+1, r+1])], axis=1)\n",
    "        #     M_21 = np.concatenate([np.zeros([2 * r + 1, r+1]), np.ones([2 * r + 1, r])], axis=1)\n",
    "        #\n",
    "        #     return torch.from_numpy((gauss*M_13)).float(), torch.from_numpy((gauss*M_23)).float(), torch.from_numpy((gauss*M_11)).float(), torch.from_numpy((gauss*M_21)).float()\n",
    "        #\n",
    "        def creat_kernel(r=1):\n",
    "\n",
    "            M_13 = np.concatenate([np.ones([r+1, 2*r+1]), np.zeros([r, 2*r+1])], axis=0)\n",
    "            M_23 = np.concatenate([np.zeros([r, 2 * r + 1]), np.ones([r+1, 2 * r + 1])], axis=0)\n",
    "\n",
    "            M_11 = np.concatenate([np.ones([2*r+1, r+1]), np.zeros([2*r+1, r])], axis=1)\n",
    "            M_21 = np.concatenate([np.zeros([2 * r + 1, r]), np.ones([2 * r + 1, r+1])], axis=1)\n",
    "\n",
    "\n",
    "            return torch.from_numpy((M_13)).float(), torch.from_numpy((M_23)).float(), torch.from_numpy((M_11)).float(), torch.from_numpy((M_21)).float()\n",
    "\n",
    "        M13, M23, M11, M21 = creat_kernel(self.k)\n",
    "\n",
    "        weight_x1 = M11.view(1, 1, self.k*2+1, self.k*2+1)\n",
    "        weight_x2 = M21.view(1, 1, self.k*2+1, self.k*2+1)\n",
    "\n",
    "        weight_y1 = M13.view(1, 1, self.k*2+1, self.k*2+1)\n",
    "        weight_y2 = M23.view(1, 1, self.k*2+1, self.k*2+1)\n",
    "\n",
    "        self.register_buffer(\"weight_x1\", weight_x1)\n",
    "        self.register_buffer(\"weight_x2\", weight_x2)\n",
    "        self.register_buffer(\"weight_y1\", weight_y1)\n",
    "        self.register_buffer(\"weight_y2\", weight_y2)\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, x):\n",
    "        # input is RGB image with shape [B 3 H W]\n",
    "        x = F.pad(x, pad=(self.k, self.k, self.k, self.k), mode=\"reflect\") + 1e-2\n",
    "        gx_1 = F.conv2d(\n",
    "            x, self.weight_x1, bias=None, stride=1, padding=0, groups=1\n",
    "        )\n",
    "        gx_2 = F.conv2d(\n",
    "            x, self.weight_x2, bias=None, stride=1, padding=0, groups=1\n",
    "        )\n",
    "        gy_1 = F.conv2d(\n",
    "            x, self.weight_y1, bias=None, stride=1, padding=0, groups=1\n",
    "        )\n",
    "        gy_2 = F.conv2d(\n",
    "            x, self.weight_y2, bias=None, stride=1, padding=0, groups=1\n",
    "        )\n",
    "        gx_rgb = torch.log((gx_1) / (gx_2))\n",
    "        gy_rgb = torch.log((gy_1) / (gy_2))\n",
    "        norm_rgb = torch.stack([gx_rgb, gy_rgb], dim=-1).norm(dim=-1)\n",
    "\n",
    "        # phase = torch.atan2(gx_rgb, gy_rgb)\n",
    "        # phase = phase / self.pi * self.nbins  # [-9, 9]\n",
    "        #\n",
    "        # b, c, h, w = norm_rgb.shape\n",
    "        # out = torch.zeros(\n",
    "        #     (b, c, self.nbins, h, w), dtype=torch.float, device=x.device\n",
    "        # )\n",
    "        # phase = phase.view(b, c, 1, h, w)\n",
    "        # norm_rgb = norm_rgb.view(b, c, 1, h, w)\n",
    "\n",
    "        # plt.subplot(111)\n",
    "        # plt.imshow(x[0].cpu().squeeze())\n",
    "        # plt.axis('off')\n",
    "        # plt.savefig(\"./origin.png\", dpi=600, bbox_inches='tight',  pad_inches = 0.0)\n",
    "        # plt.subplot(111)\n",
    "        # plt.imshow(norm_rgb[0].cpu().squeeze())\n",
    "        # plt.axis('off')\n",
    "        # plt.savefig(\"./1.png\", dpi=600, bbox_inches='tight',  pad_inches = 0.0)\n",
    "        # plt.show()\n",
    "\n",
    "        # out.scatter_add_(2, phase.floor().long() % self.nbins, norm_rgb)\n",
    "        # # b, c, 9, h, w\n",
    "        #\n",
    "        # out = out.unfold(3, self.pool, self.pool)\n",
    "        #\n",
    "        # out = out.unfold(4, self.pool, self.pool)\n",
    "        # # b, c, 9, 28, 28, self.pool, self.pool\n",
    "        # out = out.sum(dim=[-1, -2])\n",
    "        # # b, c, 9, 28, 28\n",
    "        # out = torch.nn.functional.normalize(out, p=2, dim=2) # B 1 nbins H W\n",
    "        # # b, c, 9, 28, 28\n",
    "        # tmp_hog = out.flatten(1, 2)  # return B C H W\n",
    "        # # b, 9, 28, 28\n",
    " \n",
    "\n",
    "        return norm_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_paper(image):\n",
    "    new_image = np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        if i == 2:\n",
    "            new_image[:,:,i] = np.array(image)[:,:,i]\n",
    "            continue\n",
    "        image_tensor = torch.from_numpy(np.array(image)[:,:,i]).unsqueeze(0).unsqueeze(0).float()\n",
    "        # Instantiate GF with appropriate parameters\n",
    "        sar_feature = GF(nbins=9, pool=7, kensize=1, img_size=512, patch_size=16)\n",
    "        output = sar_feature(image_tensor)\n",
    "        new_image[:,:,i] = output[0,0].cpu().numpy()\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Get an example image from your dataset (using index 1 here)\n",
    "test_image = create_image(test_dataset, 2)\n",
    "test_image = np.array(test_image).astype(np.float32)\n",
    "\n",
    "# 1. Original image (normalize for display if needed)\n",
    "original_disp = test_image / np.max(test_image)\n",
    "\n",
    "# 2. Apply Lee filter (using your lee_filter function) to channels 0 and 1.\n",
    "lee_filtered = np.zeros_like(test_image)\n",
    "lee_filtered[:,:,0] = lee_filter(test_image, 3, channel=0)\n",
    "lee_filtered[:,:,1] = lee_filter(test_image, 3, channel=1)\n",
    "# Keep channel 2 unchanged (for example, DEM or other data)\n",
    "lee_filtered[:,:,2] = test_image[:,:,2]\n",
    "lee_disp = lee_filtered / np.max(lee_filtered)\n",
    "\n",
    "# 3. Compute PMD image using your PMD_features class.\n",
    "#    Convert image to a torch tensor with shape (1, C, H, W)\n",
    "pmd_model = PMD_features([32, 64, 128, 256])\n",
    "test_tensor = torch.from_numpy(test_image).permute(2, 0, 1).unsqueeze(0)\n",
    "pmd_output = pmd_model(test_tensor)\n",
    "# Convert PMD output to a numpy array for visualization.\n",
    "# (Assuming the PMD head produces 3 channels: the first two are gradients and the third is passed through.)\n",
    "pmd_image = pmd_output[0].permute(1, 2, 0).cpu().numpy()\n",
    "pmd_disp = pmd_image / np.max(pmd_image)\n",
    "\n",
    "orig_paper_img = original_paper(test_image)\n",
    "\n",
    "# 4. Create a binary mask.\n",
    "# Here we use a simple threshold on channel 0 of the Lee-filtered image\n",
    "mask = test_dataset[2]['label']\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(18, 12))\n",
    "plt.rcParams['axes.titlesize'] = 20\n",
    "images = [original_disp, lee_disp, pmd_disp, orig_paper_img, mask]\n",
    "titles = ['Original Image', 'Lee Filtered Image', 'PMD Image', 'Original Gradient', 'Mask']\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.set_title(titles[i])\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
